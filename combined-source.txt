COMBINED SOURCE FILES
Generated: 2025-07-07T14:23:52.429Z
==================================================

PROJECT FILE TREE
=================

open-targets-mcp-server/
├── src/
│   ├── lib/
│   │   ├── ChunkingEngine.ts
│   │   ├── DataInsertionEngine.ts
│   │   ├── PaginationAnalyzer.ts
│   │   ├── SchemaInferenceEngine.ts
│   │   ├── SchemaParser.ts
│   │   └── types.ts
│   ├── index.ts
│   └── do.ts
└── wrangler.jsonc

================================================================================
FILE: src/lib/ChunkingEngine.ts
================================================================================

import { TableSchema } from "./types.js";

export interface ChunkMetadata {
	contentId: string;
	totalChunks: number;
	originalSize: number;
	contentType: 'json' | 'text';
	compressed: boolean;
	encoding?: string;
}

export interface ChunkRecord {
	id?: number;
	content_id: string;
	chunk_index: number;
	chunk_data: string;
	chunk_size: number;
}

export interface GraphQLFieldInfo {
	name: string;
	type: string;
	isList: boolean;
	isNullable: boolean;
	description?: string;
}

export interface GraphQLTypeInfo {
	name: string;
	kind: 'OBJECT' | 'SCALAR' | 'ENUM' | 'INTERFACE';
	fields: Record<string, GraphQLFieldInfo>;
	description?: string;
}

export interface GraphQLSchemaInfo {
	types: Record<string, GraphQLTypeInfo>;
	relationships: Array<{
		fromType: string;
		toType: string;
		fieldName: string;
		cardinality: string;
	}>;
}

export interface FieldChunkingRule {
	fieldName: string;
	typeName: string; // '*' for all types
	chunkThreshold: number;
	priority: 'always' | 'size-based' | 'never';
	reason?: string;
}

/**
 * ChunkingEngine handles storage and retrieval of large content by breaking it into chunks.
 * This improves performance, avoids SQLite size limits, and enables better memory management.
 * 
 * Optimized for Open Targets Platform API responses with biomedical data patterns.
 */
export class ChunkingEngine {
	private readonly CHUNK_SIZE_THRESHOLD = 32 * 1024; // 32KB - configurable
	private readonly CHUNK_SIZE = 16 * 1024; // 16KB per chunk - optimal for SQLite
	private readonly ENABLE_COMPRESSION = true; // Feature flag for compression
	
	private schemaInfo?: GraphQLSchemaInfo;
	private chunkingRules: FieldChunkingRule[] = [];

	/**
	 * Configure schema-aware chunking
	 */
	configureSchemaAwareness(schemaInfo: GraphQLSchemaInfo): void {
		this.schemaInfo = schemaInfo;
		this.generateOpenTargetsChunkingRules();
	}

	/**
	 * Generate intelligent chunking rules based on Open Targets schema patterns
	 */
	private generateOpenTargetsChunkingRules(): void {
		this.chunkingRules = [
			// Base rules that apply to all types
			{ fieldName: 'id', typeName: '*', chunkThreshold: Infinity, priority: 'never', reason: 'ID fields should never be chunked' },
			{ fieldName: 'ensemblId', typeName: '*', chunkThreshold: Infinity, priority: 'never', reason: 'Ensembl ID fields should never be chunked' },
			{ fieldName: 'efoId', typeName: '*', chunkThreshold: Infinity, priority: 'never', reason: 'EFO ID fields should never be chunked' },
			{ fieldName: 'chemblId', typeName: '*', chunkThreshold: Infinity, priority: 'never', reason: 'ChEMBL ID fields should never be chunked' },
			
			// Open Targets-specific large content fields
			{ fieldName: 'description', typeName: 'Target', chunkThreshold: 2048, priority: 'always', reason: 'Target descriptions are typically very long' },
			{ fieldName: 'description', typeName: 'Disease', chunkThreshold: 2048, priority: 'always', reason: 'Disease descriptions can be extensive' },
			{ fieldName: 'description', typeName: 'Drug', chunkThreshold: 2048, priority: 'always', reason: 'Drug descriptions can be extensive' },
			{ fieldName: 'synonyms', typeName: '*', chunkThreshold: 1024, priority: 'size-based', reason: 'Synonym arrays can be large' },
			
			// Tractability and constraint data
			{ fieldName: 'tractability', typeName: 'Target', chunkThreshold: 4096, priority: 'size-based', reason: 'Tractability data contains extensive nested information' },
			{ fieldName: 'geneticConstraint', typeName: 'Target', chunkThreshold: 2048, priority: 'size-based', reason: 'Genetic constraint data can be detailed' },
			{ fieldName: 'safety', typeName: 'Target', chunkThreshold: 4096, priority: 'size-based', reason: 'Safety information can be extensive' },
			
			// Association and evidence data
			{ fieldName: 'evidences', typeName: '*', chunkThreshold: 8192, priority: 'size-based', reason: 'Evidence arrays can be very large' },
			{ fieldName: 'associations', typeName: '*', chunkThreshold: 8192, priority: 'size-based', reason: 'Association arrays can be very large' },
			{ fieldName: 'studies', typeName: '*', chunkThreshold: 6144, priority: 'size-based', reason: 'Study arrays can be extensive' },
			
			// Pharmacovigilance and drug data
			{ fieldName: 'pharmacovigilance', typeName: 'Drug', chunkThreshold: 8192, priority: 'size-based', reason: 'Pharmacovigilance data can be very large' },
			{ fieldName: 'mechanismsOfAction', typeName: 'Drug', chunkThreshold: 4096, priority: 'size-based', reason: 'Mechanism of action data can be extensive' },
			{ fieldName: 'indications', typeName: 'Drug', chunkThreshold: 4096, priority: 'size-based', reason: 'Drug indications can be numerous' },
			
			// Ontology and classification data
			{ fieldName: 'ontology', typeName: 'Disease', chunkThreshold: 4096, priority: 'size-based', reason: 'Ontology data can contain extensive hierarchical information' },
			{ fieldName: 'therapeuticAreas', typeName: 'Disease', chunkThreshold: 2048, priority: 'size-based', reason: 'Therapeutic area data can be extensive' },
			
			// Expression and interaction data
			{ fieldName: 'expressions', typeName: 'Target', chunkThreshold: 6144, priority: 'size-based', reason: 'Expression data can be extensive across tissues' },
			{ fieldName: 'interactions', typeName: 'Target', chunkThreshold: 6144, priority: 'size-based', reason: 'Interaction data can be extensive' },
			{ fieldName: 'pathways', typeName: 'Target', chunkThreshold: 4096, priority: 'size-based', reason: 'Pathway data can be extensive' },
			
			// Conservative chunking for names and identifiers
			{ fieldName: 'approvedName', typeName: '*', chunkThreshold: 512, priority: 'size-based', reason: 'Approved names are usually short but can be long' },
			{ fieldName: 'approvedSymbol', typeName: '*', chunkThreshold: 256, priority: 'size-based', reason: 'Symbols are usually short' },
			{ fieldName: 'name', typeName: '*', chunkThreshold: 512, priority: 'size-based', reason: 'Names are usually short but can be long' },
		];

		// Generate type-specific rules based on schema analysis
		if (this.schemaInfo) {
			for (const [typeName, typeInfo] of Object.entries(this.schemaInfo.types)) {
				if (typeInfo.kind === 'OBJECT') {
					for (const [fieldName, fieldInfo] of Object.entries(typeInfo.fields)) {
						// Large list fields should be chunked aggressively
						if (fieldInfo.isList && this.isLikelyLargeContent(fieldInfo)) {
							this.chunkingRules.push({
								fieldName,
								typeName,
								chunkThreshold: 8192,
								priority: 'size-based',
								reason: `List field ${fieldName} on ${typeName} likely contains large content`
							});
						}
					}
				}
			}
		}
	}

	/**
	 * Determine if a field is likely to contain large content based on Open Targets patterns
	 */
	private isLikelyLargeContent(fieldInfo: GraphQLFieldInfo): boolean {
		const largeContentIndicators = [
			'description', 'summary', 'evidence', 'associations', 'studies',
			'tractability', 'constraint', 'safety', 'pharmacovigilance',
			'mechanisms', 'indications', 'ontology', 'expressions', 'interactions',
			'pathways', 'therapeuticAreas', 'synonyms', 'alternativeNames'
		];
		
		return largeContentIndicators.some(indicator => 
			fieldInfo.name.toLowerCase().includes(indicator) ||
			fieldInfo.description?.toLowerCase().includes(indicator)
		);
	}

	/**
	 * Schema-aware JSON stringification with intelligent chunking decisions
	 */
	async schemaAwareJsonStringify(
		obj: any, 
		typeName: string, 
		fieldName: string, 
		sql: any
	): Promise<string> {
		const jsonString = JSON.stringify(obj);
		
		// Check schema-based chunking rules first
		const applicableRule = this.getApplicableChunkingRule(fieldName, typeName);
		
		if (applicableRule) {
			if (applicableRule.priority === 'never') {
				return jsonString;
			} else if (applicableRule.priority === 'always' && jsonString.length > applicableRule.chunkThreshold) {
				const metadata = await this.storeChunkedContent(jsonString, 'json', sql);
				return this.createContentReference(metadata);
			} else if (applicableRule.priority === 'size-based' && jsonString.length > applicableRule.chunkThreshold) {
				const metadata = await this.storeChunkedContent(jsonString, 'json', sql);
				return this.createContentReference(metadata);
			}
		}
		
		// Fallback to default behavior
		if (!this.shouldChunk(jsonString)) {
			return jsonString;
		}

		const metadata = await this.storeChunkedContent(jsonString, 'json', sql);
		return this.createContentReference(metadata);
	}

	/**
	 * Get the most specific chunking rule for a field
	 */
	private getApplicableChunkingRule(fieldName: string, typeName: string): FieldChunkingRule | null {
		// Try exact type match first
		let rule = this.chunkingRules.find(r => r.fieldName === fieldName && r.typeName === typeName);
		if (rule) return rule;
		
		// Try wildcard type match
		rule = this.chunkingRules.find(r => r.fieldName === fieldName && r.typeName === '*');
		if (rule) return rule;
		
		return null;
	}

	/**
	 * Determines if content should be chunked based on size threshold
	 */
	shouldChunk(content: string): boolean {
		return content.length > this.CHUNK_SIZE_THRESHOLD;
	}

	/**
	 * Stores large content as chunks, returns metadata for retrieval
	 */
	async storeChunkedContent(
		content: string, 
		contentType: 'json' | 'text',
		sql: any
	): Promise<ChunkMetadata> {
		const contentId = this.generateContentId();
		let processedContent = content;
		let compressed = false;

		// Optional compression (when available in environment)
		if (this.ENABLE_COMPRESSION && this.shouldCompress(content)) {
			try {
				processedContent = await this.compress(content);
				compressed = true;
			} catch (error) {
				console.warn('Compression failed, storing uncompressed:', error);
				processedContent = content;
			}
		}

		// Ensure chunks table exists
		await this.ensureChunksTable(sql);

		// Split into chunks
		const chunks = this.splitIntoChunks(processedContent);
		
		// Store each chunk
		for (let i = 0; i < chunks.length; i++) {
			const chunkRecord: ChunkRecord = {
				content_id: contentId,
				chunk_index: i,
				chunk_data: chunks[i],
				chunk_size: chunks[i].length
			};
			
			await this.insertChunk(chunkRecord, sql);
		}

		// Store metadata
		const metadata: ChunkMetadata = {
			contentId,
			totalChunks: chunks.length,
			originalSize: content.length,
			contentType,
			compressed,
			encoding: compressed ? 'gzip' : undefined
		};

		await this.storeMetadata(metadata, sql);
		
		return metadata;
	}

	/**
	 * Retrieves and reassembles chunked content
	 */
	async retrieveChunkedContent(contentId: string, sql: any): Promise<string | null> {
		try {
			// Get metadata
			const metadata = await this.getMetadata(contentId, sql);
			if (!metadata) return null;

			// Retrieve all chunks in order
			const chunks = await this.getChunks(contentId, metadata.totalChunks, sql);
			if (chunks.length !== metadata.totalChunks) {
				throw new Error(`Missing chunks: expected ${metadata.totalChunks}, found ${chunks.length}`);
			}

			// Reassemble content
			const reassembled = chunks.join('');

			// Decompress if needed
			if (metadata.compressed) {
				try {
					return await this.decompress(reassembled);
				} catch (error) {
					console.error('Decompression failed:', error);
					throw new Error('Failed to decompress content');
				}
			}

			return reassembled;
		} catch (error) {
			console.error(`Failed to retrieve chunked content ${contentId}:`, error);
			return null;
		}
	}

	/**
	 * Creates a content reference for schema columns instead of storing large content directly
	 */
	createContentReference(metadata: ChunkMetadata): string {
		return `__CHUNKED__:${metadata.contentId}`;
	}

	/**
	 * Checks if a value is a chunked content reference
	 */
	isContentReference(value: any): boolean {
		return typeof value === 'string' && value.startsWith('__CHUNKED__:');
	}

	/**
	 * Extracts content ID from a content reference
	 */
	extractContentId(reference: string): string {
		return reference.replace('__CHUNKED__:', '');
	}

	/**
	 * Enhanced JSON stringification with automatic chunking
	 */
	async smartJsonStringify(obj: any, sql: any): Promise<string> {
		const jsonString = JSON.stringify(obj);
		
		if (!this.shouldChunk(jsonString)) {
			return jsonString;
		}

		// Store as chunks and return reference
		const metadata = await this.storeChunkedContent(jsonString, 'json', sql);
		return this.createContentReference(metadata);
	}

	/**
	 * Enhanced JSON parsing with automatic chunk retrieval
	 */
	async smartJsonParse(value: string, sql: any): Promise<any> {
		if (!this.isContentReference(value)) {
			return JSON.parse(value);
		}

		const contentId = this.extractContentId(value);
		const retrievedContent = await this.retrieveChunkedContent(contentId, sql);
		
		if (!retrievedContent) {
			throw new Error(`Failed to retrieve chunked content: ${contentId}`);
		}

		return JSON.parse(retrievedContent);
	}

	/**
	 * Cleanup chunked content (for maintenance)
	 */
	async cleanupChunkedContent(contentId: string, sql: any): Promise<void> {
		try {
			// Delete chunks
			sql.exec(
				`DELETE FROM content_chunks WHERE content_id = ?`,
				contentId
			);

			// Delete metadata
			sql.exec(
				`DELETE FROM chunk_metadata WHERE content_id = ?`,
				contentId
			);
		} catch (error) {
			console.error(`Failed to cleanup chunked content ${contentId}:`, error);
		}
	}

	/**
	 * Get statistics about chunked content storage
	 */
	async getChunkingStats(sql: any): Promise<any> {
		try {
			const metadataResult = sql.exec(`
				SELECT 
					COUNT(*) as total_chunked_items,
					SUM(original_size) as total_original_size,
					AVG(original_size) as avg_original_size,
					SUM(total_chunks) as total_chunks,
					COUNT(CASE WHEN compressed = 1 THEN 1 END) as compressed_items
				FROM chunk_metadata
			`).one();

			const chunksResult = sql.exec(`
				SELECT 
					COUNT(*) as total_chunk_records,
					SUM(chunk_size) as total_stored_size,
					AVG(chunk_size) as avg_chunk_size
				FROM content_chunks
			`).one();

			return {
				metadata: metadataResult || {},
				chunks: chunksResult || {},
				compression_ratio: metadataResult?.total_original_size && chunksResult?.total_stored_size 
					? (metadataResult.total_original_size / chunksResult.total_stored_size).toFixed(2)
					: null
			};
		} catch (error) {
			return { error: error instanceof Error ? error.message : 'Failed to get stats' };
		}
	}

	/**
	 * Analyze chunking effectiveness and provide Open Targets-specific recommendations
	 */
	async analyzeChunkingEffectiveness(sql: any): Promise<any> {
		const stats = await this.getChunkingStats(sql);
		
		if (!this.schemaInfo) {
			return {
				...stats,
				recommendation: "Enable schema-aware chunking by providing Open Targets GraphQL schema",
				schema_awareness: false
			};
		}

		// Analyze which fields are being chunked most
		const fieldAnalysis = await this.analyzeChunkedFields(sql);
		
		return {
			...stats,
			schema_awareness: true,
			field_analysis: fieldAnalysis,
			recommendations: this.generateOpenTargetsRecommendations(fieldAnalysis)
		};
	}

	private async analyzeChunkedFields(sql: any): Promise<any> {
		try {
			const result = sql.exec(`
				SELECT 
					content_type,
					original_size,
					compressed,
					COUNT(*) as chunk_count
				FROM chunk_metadata 
				GROUP BY content_type, compressed
				ORDER BY chunk_count DESC
			`).toArray();
			
			return result;
		} catch (error) {
			return { error: "Could not analyze chunked fields" };
		}
	}

	private generateOpenTargetsRecommendations(fieldAnalysis: any): string[] {
		const recommendations = [];
		
		if (this.chunkingRules.length === 0) {
			recommendations.push("Configure Open Targets-specific chunking rules based on your data patterns");
		}
		
		if (fieldAnalysis && fieldAnalysis.length > 0) {
			const uncompressedCount = fieldAnalysis.filter((f: any) => !f.compressed).length;
			if (uncompressedCount > 0) {
				recommendations.push("Enable compression for better storage efficiency of biomedical data");
			}
		}
		
		recommendations.push("Monitor chunk size distribution for target/disease/drug association queries");
		recommendations.push("Consider pagination for large association queries to optimize performance");
		
		return recommendations;
	}

	// Private helper methods

	private generateContentId(): string {
		return 'chunk_' + crypto.randomUUID().replace(/-/g, '');
	}

	private shouldCompress(content: string): boolean {
		// Compress content larger than 8KB (good compression threshold)
		return content.length > 8192;
	}

	private async compress(content: string): Promise<string> {
		try {
			const uint8Array = new TextEncoder().encode(content);
			
			// Check if CompressionStream is available (modern browsers/runtimes)
			if (typeof CompressionStream !== 'undefined') {
				const compressionStream = new CompressionStream('gzip');
				const writer = compressionStream.writable.getWriter();
				const reader = compressionStream.readable.getReader();
				
				writer.write(uint8Array);
				writer.close();
				
				const chunks: Uint8Array[] = [];
				let result = await reader.read();
				while (!result.done) {
					chunks.push(result.value);
					result = await reader.read();
				}
				
				// Combine chunks and encode to base64
				const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
				const combined = new Uint8Array(totalLength);
				let offset = 0;
				for (const chunk of chunks) {
					combined.set(chunk, offset);
					offset += chunk.length;
				}
				
				return btoa(String.fromCharCode(...combined));
			}
			
			// Fallback to simple base64 encoding (not real compression)
			return btoa(content);
		} catch (error) {
			throw new Error(`Compression failed: ${error}`);
		}
	}

	private async decompress(compressedContent: string): Promise<string> {
		try {
			// Check if DecompressionStream is available
			if (typeof DecompressionStream !== 'undefined') {
				const compressedData = Uint8Array.from(atob(compressedContent), c => c.charCodeAt(0));
				
				const decompressionStream = new DecompressionStream('gzip');
				const writer = decompressionStream.writable.getWriter();
				const reader = decompressionStream.readable.getReader();
				
				writer.write(compressedData);
				writer.close();
				
				const chunks: Uint8Array[] = [];
				let result = await reader.read();
				while (!result.done) {
					chunks.push(result.value);
					result = await reader.read();
				}
				
				const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
				const combined = new Uint8Array(totalLength);
				let offset = 0;
				for (const chunk of chunks) {
					combined.set(chunk, offset);
					offset += chunk.length;
				}
				
				return new TextDecoder().decode(combined);
			}
			
			// Fallback from base64
			return atob(compressedContent);
		} catch (error) {
			throw new Error(`Decompression failed: ${error}`);
		}
	}

	private splitIntoChunks(content: string): string[] {
		const chunks: string[] = [];
		for (let i = 0; i < content.length; i += this.CHUNK_SIZE) {
			chunks.push(content.slice(i, i + this.CHUNK_SIZE));
		}
		return chunks;
	}

	private async ensureChunksTable(sql: any): Promise<void> {
		// Create chunks table
		sql.exec(`
			CREATE TABLE IF NOT EXISTS content_chunks (
				id INTEGER PRIMARY KEY AUTOINCREMENT,
				content_id TEXT NOT NULL,
				chunk_index INTEGER NOT NULL,
				chunk_data TEXT NOT NULL,
				chunk_size INTEGER NOT NULL,
				created_at TEXT DEFAULT CURRENT_TIMESTAMP,
				UNIQUE(content_id, chunk_index)
			)
		`);

		// Create metadata table
		sql.exec(`
			CREATE TABLE IF NOT EXISTS chunk_metadata (
				content_id TEXT PRIMARY KEY,
				total_chunks INTEGER NOT NULL,
				original_size INTEGER NOT NULL,
				content_type TEXT NOT NULL,
				compressed INTEGER DEFAULT 0,
				encoding TEXT,
				created_at TEXT DEFAULT CURRENT_TIMESTAMP
			)
		`);

		// Create indexes for performance
		sql.exec(`CREATE INDEX IF NOT EXISTS idx_content_chunks_lookup ON content_chunks(content_id, chunk_index)`);
		sql.exec(`CREATE INDEX IF NOT EXISTS idx_chunk_metadata_size ON chunk_metadata(original_size)`);
	}

	private async insertChunk(chunk: ChunkRecord, sql: any): Promise<void> {
		sql.exec(
			`INSERT INTO content_chunks (content_id, chunk_index, chunk_data, chunk_size) 
			 VALUES (?, ?, ?, ?)`,
			chunk.content_id,
			chunk.chunk_index, 
			chunk.chunk_data,
			chunk.chunk_size
		);
	}

	private async storeMetadata(metadata: ChunkMetadata, sql: any): Promise<void> {
		sql.exec(
			`INSERT INTO chunk_metadata (content_id, total_chunks, original_size, content_type, compressed, encoding)
			 VALUES (?, ?, ?, ?, ?, ?)`,
			metadata.contentId,
			metadata.totalChunks,
			metadata.originalSize,
			metadata.contentType,
			metadata.compressed ? 1 : 0,
			metadata.encoding || null
		);
	}

	private async getMetadata(contentId: string, sql: any): Promise<ChunkMetadata | null> {
		const result = sql.exec(
			`SELECT * FROM chunk_metadata WHERE content_id = ?`,
			contentId
		).one();

		if (!result) return null;

		return {
			contentId: result.content_id,
			totalChunks: result.total_chunks,
			originalSize: result.original_size,
			contentType: result.content_type,
			compressed: Boolean(result.compressed),
			encoding: result.encoding
		};
	}

	private async getChunks(contentId: string, expectedCount: number, sql: any): Promise<string[]> {
		const results = sql.exec(
			`SELECT chunk_data FROM content_chunks 
			 WHERE content_id = ? 
			 ORDER BY chunk_index ASC`,
			contentId
		).toArray();

		return results.map((row: any) => row.chunk_data);
	}
} 
--------------------------------------------------------------------------------
END OF FILE: src/lib/ChunkingEngine.ts
--------------------------------------------------------------------------------


================================================================================
FILE: src/lib/DataInsertionEngine.ts
================================================================================

import { TableSchema } from "./types.js";
import { ChunkingEngine } from "./ChunkingEngine.js";
import { SchemaParser, FieldExtractionRule } from "./SchemaParser.js";

export class DataInsertionEngine {
	private chunkingEngine = new ChunkingEngine();
	private schemaParser = new SchemaParser();
	private processedEntities: Map<string, Map<any, number>> = new Map();
	private relationshipData: Map<string, Set<string>> = new Map(); // Track actual relationships found in data
	private extractionRules: FieldExtractionRule[] = [];
	
	/**
	 * Configure schema-aware entity extraction
	 */
	configureSchemaAwareExtraction(schemaContent: string): void {
		const schemaInfo = this.schemaParser.parseSchemaContent(schemaContent);
		this.extractionRules = this.schemaParser.getExtractionRules();
		this.chunkingEngine.configureSchemaAwareness(schemaInfo);
	}

	/**
	 * Check if entities should be extracted from a field based on schema rules
	 */
	private shouldExtractEntitiesFromField(typeName: string, fieldName: string): {
		extract: boolean;
		targetType?: string;
		isListField: boolean;
	} {
		return this.schemaParser.shouldExtractEntities(typeName, fieldName);
	}

	async insertData(data: any, schemas: Record<string, TableSchema>, sql: any): Promise<void> {
		// Reset state for new insertion
		this.processedEntities.clear();
		this.relationshipData.clear();

		const schemaNames = Object.keys(schemas);

		// Check if this is one of the simple fallback schemas
		if (schemaNames.length === 1 && (schemaNames[0] === 'scalar_data' || schemaNames[0] === 'array_data' || schemaNames[0] === 'root_object')) {
			const tableName = schemaNames[0];
			const schema = schemas[tableName];
			if (tableName === 'scalar_data' || tableName === 'root_object') {
				await this.insertSimpleRow(data, tableName, schema, sql);
			} else { // array_data
				if (Array.isArray(data)) {
					for (const item of data) {
						await this.insertSimpleRow(item, tableName, schema, sql);
					}
				} else {
					await this.insertSimpleRow(data, tableName, schema, sql); 
				}
			}
			return;
		}

		// Phase 1: Insert all entities first (to establish primary keys)
		await this.insertAllEntities(data, schemas, sql);
		
		// Phase 2: Handle relationships via junction tables (only for tables with data)
		await this.insertJunctionTableRecords(data, schemas, sql);
	}

	private async insertAllEntities(obj: any, schemas: Record<string, TableSchema>, sql: any, path: string[] = []): Promise<void> {
		if (!obj || typeof obj !== 'object') return;
		
		// Handle arrays of entities
		if (Array.isArray(obj)) {
			for (const item of obj) {
				await this.insertAllEntities(item, schemas, sql, path);
			}
			return;
		}
		
		// Handle GraphQL edges pattern
		if (obj.edges && Array.isArray(obj.edges)) {
			const nodes = obj.edges.map((edge: any) => edge.node).filter(Boolean);
			for (const node of nodes) {
				await this.insertAllEntities(node, schemas, sql, path);
			}
			return;
		}
		
		// Handle GraphQL rows pattern (Open Targets uses this)
		if (obj.rows && Array.isArray(obj.rows)) {
			for (const row of obj.rows) {
				await this.insertAllEntities(row, schemas, sql, path);
			}
			return;
		}
		
		// Handle individual entities
		if (this.isEntity(obj)) {
			const entityType = this.inferEntityType(obj, path);
			if (schemas[entityType]) {
				await this.insertEntityRecord(obj, entityType, schemas[entityType], sql);
				
				// Process nested entities and record relationships
				await this.processEntityRelationships(obj, entityType, schemas, sql, path);
			}
		}
		
		// Recursively explore nested objects
		for (const [key, value] of Object.entries(obj)) {
			await this.insertAllEntities(value, schemas, sql, [...path, key]);
		}
	}
	
	private async processEntityRelationships(entity: any, entityType: string, schemas: Record<string, TableSchema>, sql: any, path: string[]): Promise<void> {
		for (const [key, value] of Object.entries(entity)) {
			if (Array.isArray(value) && value.length > 0) {
				// Check if this array contains entities using schema information
				const extractionInfo = this.shouldExtractEntitiesFromField(entityType, key);
				
				if (extractionInfo.extract && value.length > 0 && this.isEntity(value[0])) {
					const relatedEntityType = extractionInfo.targetType || this.inferEntityType(value[0], [key]);
					
					// Process all entities in this array and record relationships
					for (const item of value) {
						if (this.isEntity(item) && schemas[relatedEntityType]) {
							await this.insertEntityRecord(item, relatedEntityType, schemas[relatedEntityType], sql);
							
							// Track this relationship for junction table creation
							const relationshipKey = [entityType, relatedEntityType].sort().join('_');
							const relationships = this.relationshipData.get(relationshipKey) || new Set();
							const entityId = this.getEntityId(entity, entityType);
							const relatedId = this.getEntityId(item, relatedEntityType);
							
							if (entityId && relatedId) {
								relationships.add(`${entityId}_${relatedId}`);
								this.relationshipData.set(relationshipKey, relationships);
							}
							
							// Recursively process nested entities
							await this.processEntityRelationships(item, relatedEntityType, schemas, sql, [...path, key]);
						}
					}
				} else {
					// Fallback to original logic for non-schema-guided extraction
					const firstItem = value.find(item => this.isEntity(item));
					if (firstItem) {
						const relatedEntityType = this.inferEntityType(firstItem, [key]);
						
						// Process all entities in this array and record relationships
						for (const item of value) {
							if (this.isEntity(item) && schemas[relatedEntityType]) {
								await this.insertEntityRecord(item, relatedEntityType, schemas[relatedEntityType], sql);
								
								// Track this relationship for junction table creation
								const relationshipKey = [entityType, relatedEntityType].sort().join('_');
								const relationships = this.relationshipData.get(relationshipKey) || new Set();
								const entityId = this.getEntityId(entity, entityType);
								const relatedId = this.getEntityId(item, relatedEntityType);
								
								if (entityId && relatedId) {
									relationships.add(`${entityId}_${relatedId}`);
									this.relationshipData.set(relationshipKey, relationships);
								}
								
								// Recursively process nested entities
								await this.processEntityRelationships(item, relatedEntityType, schemas, sql, [...path, key]);
							}
						}
					}
				}
			} else if (value && typeof value === 'object' && this.isEntity(value)) {
				// Single related entity
				const relatedEntityType = this.inferEntityType(value, [key]);
				if (schemas[relatedEntityType]) {
					await this.insertEntityRecord(value, relatedEntityType, schemas[relatedEntityType], sql);
					await this.processEntityRelationships(value, relatedEntityType, schemas, sql, [...path, key]);
				}
			}
		}
	}
	
	private async insertEntityRecord(entity: any, tableName: string, schema: TableSchema, sql: any): Promise<number | null> {
		// Check if this entity was already processed
		const entityMap = this.processedEntities.get(tableName) || new Map();
		if (entityMap.has(entity)) {
			return entityMap.get(entity)!;
		}
		
		const rowData = await this.mapEntityToSchema(entity, schema, sql);
		if (Object.keys(rowData).length === 0) return null;
		
		const columns = Object.keys(rowData);
		const placeholders = columns.map(() => '?').join(', ');
		const values = Object.values(rowData);
		
		// Use INSERT OR IGNORE to handle potential duplicates
		const insertSQL = `INSERT OR IGNORE INTO ${tableName} (${columns.join(', ')}) VALUES (${placeholders})`;
		sql.exec(insertSQL, ...values);
		
		// Get the inserted or existing ID
		let insertedId: number | null = null;
		if (rowData.id) {
			// If we have the ID in the data, use it
			insertedId = rowData.id;
		} else {
			// Otherwise get the last inserted row ID
			insertedId = sql.exec(`SELECT last_insert_rowid() as id`).one()?.id || null;
		}
		
		// Track this entity
		if (insertedId) {
			entityMap.set(entity, insertedId);
			this.processedEntities.set(tableName, entityMap);
		}
		
		return insertedId;
	}
	
	private async insertJunctionTableRecords(data: any, schemas: Record<string, TableSchema>, sql: any): Promise<void> {
		// Only create junction table records for relationships that actually have data
		for (const [relationshipKey, relationshipPairs] of this.relationshipData.entries()) {
			if (schemas[relationshipKey]) {
				const [table1, table2] = relationshipKey.split('_');
				
				for (const pairKey of relationshipPairs) {
					const [id1, id2] = pairKey.split('_').map(Number);
					
					const insertSQL = `INSERT OR IGNORE INTO ${relationshipKey} (${table1}_id, ${table2}_id) VALUES (?, ?)`;
					sql.exec(insertSQL, id1, id2);
				}
			}
		}
	}
	
	private getEntityId(entity: any, entityType: string): number | null {
		const entityMap = this.processedEntities.get(entityType);
		return entityMap?.get(entity) || null;
	}
	
	private async mapEntityToSchema(obj: any, schema: TableSchema, sql: any): Promise<any> {
		const rowData: any = {};
		
		if (!obj || typeof obj !== 'object') {
			if (schema.columns.value) rowData.value = obj;
			return rowData;
		}
		
		for (const columnName of Object.keys(schema.columns)) {
			if (columnName === 'id' && schema.columns[columnName].includes('AUTOINCREMENT')) {
				continue;
			}
			
			let value = null;
			
			// Handle foreign key columns
			if (columnName.endsWith('_id') && !columnName.includes('_json')) {
				const baseKey = columnName.slice(0, -3);
				const originalKey = this.findOriginalKey(obj, baseKey);
				if (originalKey && obj[originalKey] && typeof obj[originalKey] === 'object') {
					value = (obj[originalKey] as any).id || null;
				}
			}
			// Handle prefixed columns (from nested scalar fields)
			else if (columnName.includes('_') && !columnName.endsWith('_json')) {
				const parts = columnName.split('_');
				if (parts.length >= 2) {
					const baseKey = parts[0];
					const subKey = parts.slice(1).join('_');
					const originalKey = this.findOriginalKey(obj, baseKey);
					if (originalKey && obj[originalKey] && typeof obj[originalKey] === 'object') {
						const nestedObj = obj[originalKey];
						const originalSubKey = this.findOriginalKey(nestedObj, subKey);
						if (originalSubKey && nestedObj[originalSubKey] !== undefined) {
							value = nestedObj[originalSubKey];
							if (typeof value === 'boolean') value = value ? 1 : 0;
						}
					}
				}
			}
			// Handle JSON columns with chunking
			else if (columnName.endsWith('_json')) {
				const baseKey = columnName.slice(0, -5);
				const originalKey = this.findOriginalKey(obj, baseKey);
				if (originalKey && obj[originalKey] && typeof obj[originalKey] === 'object') {
					value = await this.chunkingEngine.smartJsonStringify(obj[originalKey], sql);
				}
			}
			// Handle regular columns
			else {
				const originalKey = this.findOriginalKey(obj, columnName);
				if (originalKey && obj[originalKey] !== undefined) {
					value = obj[originalKey];
					if (typeof value === 'boolean') value = value ? 1 : 0;
					
					// Skip arrays of entities (they're handled via junction tables)
					if (Array.isArray(value) && value.length > 0 && this.isEntity(value[0])) {
						continue;
					}
				}
			}
			
			if (value !== null && value !== undefined) {
				rowData[columnName] = value;
			}
		}
		
		return rowData;
	}
	
	// Entity detection and type inference (adapted for Open Targets patterns)
	private isEntity(obj: any): boolean {
		if (!obj || typeof obj !== 'object' || Array.isArray(obj)) return false;
		
		// Open Targets entities typically have ID fields or key identifiers
		const hasId = obj.id !== undefined || obj._id !== undefined || 
			obj.ensemblId !== undefined || obj.efoId !== undefined || obj.chemblId !== undefined;
		const fieldCount = Object.keys(obj).length;
		const hasMultipleFields = fieldCount >= 2;
		
		// Check for Open Targets-specific entity patterns
		const hasEntityFields = obj.name !== undefined || obj.approvedSymbol !== undefined || 
			obj.description !== undefined || obj.type !== undefined || obj.score !== undefined;
		
		return hasId || (hasMultipleFields && hasEntityFields);
	}
	
	private inferEntityType(obj: any, path: string[]): string {
		// Try to infer type from object properties (e.g., __typename)
		if (obj.__typename) return this.sanitizeTableName(obj.__typename);
		if (obj.type && typeof obj.type === 'string') return this.sanitizeTableName(obj.type);
		
		// Special Open Targets patterns
		if (obj.ensemblId) return 'target';
		if (obj.efoId) return 'disease';
		if (obj.chemblId) return 'drug';
		if (obj.approvedSymbol) return 'target';
		
		// Infer from path context, attempting to singularize
		if (path.length > 0) {
			const lastPath = path[path.length - 1];
			if (lastPath === 'edges' && path.length > 1) {
				return this.sanitizeTableName(path[path.length - 2]);
			}
			if (lastPath === 'rows' && path.length > 1) {
				return this.sanitizeTableName(path[path.length - 2]);
			}
			if (lastPath.endsWith('s') && lastPath.length > 1) {
				return this.sanitizeTableName(lastPath.slice(0, -1));
			}
			return this.sanitizeTableName(lastPath);
		}
		
		return 'entity_' + Math.random().toString(36).substr(2, 9);
	}
	
	private sanitizeTableName(name: string): string {
		if (!name || typeof name !== 'string') {
			return 'table_' + Math.random().toString(36).substr(2, 9);
		}
		
		let sanitized = name
			.replace(/[^a-zA-Z0-9_]/g, '_')
			.replace(/_{2,}/g, '_')  // Replace multiple underscores with single
			.replace(/^_|_$/g, '')  // Remove leading/trailing underscores
			.toLowerCase();
		
		// Ensure it doesn't start with a number
		if (/^[0-9]/.test(sanitized)) {
			sanitized = 'table_' + sanitized;
		}
		
		// Ensure it's not empty and not a SQL keyword
		if (!sanitized || sanitized.length === 0) {
			sanitized = 'table_' + Math.random().toString(36).substr(2, 9);
		}
		
		// Handle SQL reserved words
		const reservedWords = ['table', 'index', 'view', 'column', 'primary', 'key', 'foreign', 'constraint'];
		if (reservedWords.includes(sanitized)) {
			sanitized = sanitized + '_table';
		}
		
		return sanitized;
	}
	
	private findOriginalKey(obj: any, sanitizedKey: string): string | null {
		const keys = Object.keys(obj);
		
		// Direct match
		if (keys.includes(sanitizedKey)) return sanitizedKey;
		
		// Find key that sanitizes to the same value
		return keys.find(key => 
			this.sanitizeColumnName(key) === sanitizedKey
		) || null;
	}
	
	private sanitizeColumnName(name: string): string {
		if (!name || typeof name !== 'string') {
			return 'column_' + Math.random().toString(36).substr(2, 9);
		}
		
		// Convert camelCase to snake_case
		let snakeCase = name
			.replace(/([A-Z])/g, '_$1')
			.toLowerCase()
			.replace(/[^a-zA-Z0-9_]/g, '_')
			.replace(/_{2,}/g, '_')  // Replace multiple underscores with single
			.replace(/^_|_$/g, ''); // Remove leading/trailing underscores
		
		// Ensure it doesn't start with a number
		if (/^[0-9]/.test(snakeCase)) {
			snakeCase = 'col_' + snakeCase;
		}
		
		// Ensure it's not empty
		if (!snakeCase || snakeCase.length === 0) {
			snakeCase = 'column_' + Math.random().toString(36).substr(2, 9);
		}
		
		// Handle Open Targets-specific naming patterns
		const openTargetsTerms: Record<string, string> = {
			'ensemblid': 'ensembl_id',
			'efoid': 'efo_id', 
			'chemblid': 'chembl_id',
			'approvedsymbol': 'approved_symbol',
			'approvedname': 'approved_name',
			'geneticconstraint': 'genetic_constraint',
			'mechanismsofaction': 'mechanisms_of_action',
			'therapeuticareas': 'therapeutic_areas',
			'pharmacovigilance': 'pharmacovigilance'
		};
		
		const result = openTargetsTerms[snakeCase] || snakeCase;
		
		// Handle SQL reserved words
		const reservedWords = ['table', 'index', 'view', 'column', 'primary', 'key', 'foreign', 'constraint', 'order', 'group', 'select', 'from', 'where'];
		if (reservedWords.includes(result)) {
			return result + '_col';
		}
		
		return result;
	}

	private async insertSimpleRow(obj: any, tableName: string, schema: TableSchema, sql: any): Promise<void> {
		const rowData = await this.mapObjectToSimpleSchema(obj, schema, sql);
		if (Object.keys(rowData).length === 0 && !(tableName === 'scalar_data' && obj === null)) return; // Allow inserting null for scalar_data

		const columns = Object.keys(rowData);
		const placeholders = columns.map(() => '?').join(', ');
		const values = Object.values(rowData);

		const insertSQL = `INSERT INTO ${tableName} (${columns.join(', ')}) VALUES (${placeholders})`;
		sql.exec(insertSQL, ...values);
	}

	private async mapObjectToSimpleSchema(obj: any, schema: TableSchema, sql: any): Promise<any> {
		const rowData: any = {};

		if (obj === null || typeof obj !== 'object') {
			if (schema.columns.value) { // For scalar_data or array_data of primitives
				rowData.value = obj;
			} else if (Object.keys(schema.columns).length > 0) {
				// This case should ideally not be hit if schema generation is right for primitives
				// but as a fallback, if there's a column, try to put it there.
				const firstCol = Object.keys(schema.columns)[0];
				rowData[firstCol] = obj;
			}
			return rowData;
		}

		if (Array.isArray(obj)) { // For root_object schemas where a field might be an array
			// This function (mapObjectToSimpleSchema) is for a single row. If an array needs to be a column, it should be JSON.
			// This case likely means the schema is `root_object` and `obj` is one of its fields being mapped.
			// The schema definition for `root_object` via `extractSimpleFields` handles JSON stringification.
			// So, this specific path in mapObjectToSimpleSchema might be redundant if schema is well-defined.
			// For safety, if a column expects `_json` for this array, it will be handled by the loop below.
		}

		for (const columnName of Object.keys(schema.columns)) {
			let valueToInsert = undefined;
			let originalKeyFound = false;

			if (columnName.endsWith('_json')) {
				const baseKey = columnName.slice(0, -5);
				const originalKey = this.findOriginalKey(obj, baseKey);
				if (originalKey && obj[originalKey] !== undefined) {
					valueToInsert = await this.chunkingEngine.smartJsonStringify(obj[originalKey], sql);
					originalKeyFound = true;
				}
			} else {
				const originalKey = this.findOriginalKey(obj, columnName);
				if (originalKey && obj[originalKey] !== undefined) {
					const val = obj[originalKey];
					if (typeof val === 'boolean') {
						valueToInsert = val ? 1 : 0;
					} else if (typeof val === 'object' && val !== null) {
						// This should not happen if schema is from extractSimpleFields, which JSONifies nested objects.
						// If it does, it implies a mismatch. For safety, try to JSON stringify.
						valueToInsert = await this.chunkingEngine.smartJsonStringify(val, sql);
					} else {
						valueToInsert = val;
					}
					originalKeyFound = true;
				}
			}

			if (originalKeyFound && valueToInsert !== undefined) {
				rowData[columnName] = valueToInsert;
			} else if (obj.hasOwnProperty(columnName) && obj[columnName] !== undefined){ // Direct match as last resort
				// This handles cases where sanitized names might not be used or `findOriginalKey` fails but direct prop exists
				const val = obj[columnName];
				if (typeof val === 'boolean') valueToInsert = val ? 1:0;
				else if (typeof val === 'object' && val !== null) valueToInsert = await this.chunkingEngine.smartJsonStringify(val, sql);
				else valueToInsert = val;
				rowData[columnName] = valueToInsert;
			}
		}
		return rowData;
	}
} 
--------------------------------------------------------------------------------
END OF FILE: src/lib/DataInsertionEngine.ts
--------------------------------------------------------------------------------


================================================================================
FILE: src/lib/PaginationAnalyzer.ts
================================================================================

import { PaginationInfo } from "./types.js";

export class PaginationAnalyzer {
	
	static extractInfo(data: any): PaginationInfo {
		const result: PaginationInfo = {
			hasNextPage: false,
			hasPreviousPage: false,
			currentCount: 0,
			totalCount: null,
			endCursor: null,
			startCursor: null
		};
		
		const pageInfo = this.findPageInfo(data);
		if (pageInfo) {
			Object.assign(result, {
				hasNextPage: pageInfo.hasNextPage || false,
				hasPreviousPage: pageInfo.hasPreviousPage || false,
				endCursor: pageInfo.endCursor,
				startCursor: pageInfo.startCursor
			});
		}
		
		result.totalCount = this.findTotalCount(data);
		result.currentCount = this.countCurrentItems(data);
		
		if (result.hasNextPage) {
			result.suggestion = `Use pagination to get more than ${result.currentCount} records. Add "pageInfo { hasNextPage endCursor }" to your query and use "after: \"${result.endCursor}\"" for next page.`;
		}
		
		return result;
	}
	
	private static findPageInfo(obj: any): any {
		if (!obj || typeof obj !== 'object') return null;
		if (obj.pageInfo && typeof obj.pageInfo === 'object') return obj.pageInfo;
		
		for (const value of Object.values(obj)) {
			const found = this.findPageInfo(value);
			if (found) return found;
		}
		return null;
	}
	
	private static findTotalCount(obj: any): number | null {
		if (!obj || typeof obj !== 'object') return null;
		if (typeof obj.totalCount === 'number') return obj.totalCount;
		
		for (const value of Object.values(obj)) {
			const found = this.findTotalCount(value);
			if (found !== null) return found;
		}
		return null;
	}
	
	private static countCurrentItems(obj: any): number {
		// Count edges arrays first
		const edgesArrays: any[][] = [];
		this.findEdgesArrays(obj, edgesArrays);
		
		if (edgesArrays.length > 0) {
			return edgesArrays.reduce((sum, edges) => sum + edges.length, 0);
		}
		
		// Fallback to general array counting
		return this.countArrayItems(obj);
	}
	
	private static findEdgesArrays(obj: any, result: any[][]): void {
		if (!obj || typeof obj !== 'object') return;
		if (Array.isArray(obj.edges)) result.push(obj.edges);
		
		for (const value of Object.values(obj)) {
			this.findEdgesArrays(value, result);
		}
	}
	
	private static countArrayItems(obj: any): number {
		if (!obj || typeof obj !== 'object') return 0;
		
		let count = 0;
		for (const value of Object.values(obj)) {
			if (Array.isArray(value)) {
				count += value.length;
			} else if (typeof value === 'object') {
				count += this.countArrayItems(value);
			}
		}
		return count;
	}
} 
--------------------------------------------------------------------------------
END OF FILE: src/lib/PaginationAnalyzer.ts
--------------------------------------------------------------------------------


================================================================================
FILE: src/lib/SchemaInferenceEngine.ts
================================================================================

import { TableSchema } from "./types.js";
import { ChunkingEngine } from "./ChunkingEngine.js";

// Enhanced schema inference engine with proper relational decomposition for Open Targets data
export class SchemaInferenceEngine {
	private chunkingEngine = new ChunkingEngine();
	private discoveredEntities: Map<string, any[]> = new Map();
	private entityRelationships: Map<string, Set<string>> = new Map(); // Now tracks unique relationships only
	
	inferFromJSON(data: any): Record<string, TableSchema> {
		// Reset state for new inference
		this.discoveredEntities.clear();
		this.entityRelationships.clear();
		
		const schemas: Record<string, TableSchema> = {};
		
		this.discoverEntities(data, []);
		
		// Only proceed if we found meaningful entities
		if (this.discoveredEntities.size > 0) {
			this.createSchemasFromEntities(schemas);
		} else {
			// Fallback for simple data
			if (typeof data !== 'object' || data === null || Array.isArray(data)) {
				const tableName = Array.isArray(data) ? 'array_data' : 'scalar_data';
				schemas[tableName] = this.createSchemaFromPrimitiveOrSimpleArray(data, tableName);
			} else {
				schemas.root_object = this.createSchemaFromObject(data, 'root_object');
			}
		}

		return schemas;
	}
	
	private discoverEntities(obj: any, path: string[], parentEntityType?: string): void {
		if (!obj || typeof obj !== 'object') {
			return;
		}

		if (Array.isArray(obj)) {
			if (obj.length > 0) {
				// Process all items in the array - they should be the same entity type
				let arrayEntityType: string | null = null;
				
				for (const item of obj) {
					if (this.isEntity(item)) {
						if (!arrayEntityType) {
							arrayEntityType = this.inferEntityType(item, path);
						}
						
						// Add to discovered entities
						const entitiesOfType = this.discoveredEntities.get(arrayEntityType) || [];
						entitiesOfType.push(item);
						this.discoveredEntities.set(arrayEntityType, entitiesOfType);
						
						// Record relationship if this array belongs to a parent entity
						if (parentEntityType && path.length > 0) {
							const fieldName = path[path.length - 1];
							if (fieldName !== 'nodes' && fieldName !== 'edges') { // Skip GraphQL wrapper fields
								this.recordRelationship(parentEntityType, arrayEntityType);
							}
						}
						
						// Recursively process nested objects within this entity
						this.processEntityProperties(item, arrayEntityType);
					}
				}
			}
			return;
		}

		// Handle GraphQL edges pattern (common in Open Targets)
		if (obj.edges && Array.isArray(obj.edges)) {
			const nodes = obj.edges.map((edge: any) => edge.node).filter(Boolean);
			if (nodes.length > 0) {
				this.discoverEntities(nodes, path, parentEntityType);
			}
			return;
		}

		// Handle GraphQL rows pattern (also used in Open Targets)
		if (obj.rows && Array.isArray(obj.rows)) {
			this.discoverEntities(obj.rows, path, parentEntityType);
			return;
		}

		// Process individual entities
		if (this.isEntity(obj)) {
			const entityType = this.inferEntityType(obj, path);
			
			// Add to discovered entities
			const entitiesOfType = this.discoveredEntities.get(entityType) || [];
			entitiesOfType.push(obj);
			this.discoveredEntities.set(entityType, entitiesOfType);
			
			// Process properties of this entity
			this.processEntityProperties(obj, entityType);
			return;
		}

		// For non-entity objects, recursively explore their properties
		for (const [key, value] of Object.entries(obj)) {
			this.discoverEntities(value, [...path, key], parentEntityType);
		}
	}
	
	private processEntityProperties(entity: any, entityType: string): void {
		for (const [key, value] of Object.entries(entity)) {
			if (Array.isArray(value) && value.length > 0) {
				// Check if this array contains entities
				const firstItem = value.find(item => this.isEntity(item));
				if (firstItem) {
					const relatedEntityType = this.inferEntityType(firstItem, [key]);
					this.recordRelationship(entityType, relatedEntityType);
					
					// Process all entities in this array
					value.forEach(item => {
						if (this.isEntity(item)) {
							const entitiesOfType = this.discoveredEntities.get(relatedEntityType) || [];
							entitiesOfType.push(item);
							this.discoveredEntities.set(relatedEntityType, entitiesOfType);
							
							// Recursively process nested entities
							this.processEntityProperties(item, relatedEntityType);
						}
					});
				}
			} else if (value && typeof value === 'object' && this.isEntity(value)) {
				// Single related entity
				const relatedEntityType = this.inferEntityType(value, [key]);
				this.recordRelationship(entityType, relatedEntityType);
				
				const entitiesOfType = this.discoveredEntities.get(relatedEntityType) || [];
				entitiesOfType.push(value);
				this.discoveredEntities.set(relatedEntityType, entitiesOfType);
				
				// Recursively process nested entities
				this.processEntityProperties(value, relatedEntityType);
			}
		}
	}
	
	private isEntity(obj: any): boolean {
		if (!obj || typeof obj !== 'object' || Array.isArray(obj)) return false;
		
		// An entity typically has an ID field or multiple meaningful fields
		const hasId = obj.id !== undefined || obj._id !== undefined || 
			obj.ensemblId !== undefined || obj.efoId !== undefined || obj.chemblId !== undefined;
		const fieldCount = Object.keys(obj).length;
		const hasMultipleFields = fieldCount >= 2;
		
		// Check for Open Targets-specific entity patterns
		const hasEntityFields = obj.name !== undefined || obj.approvedSymbol !== undefined || 
			obj.description !== undefined || obj.type !== undefined || obj.score !== undefined;
		
		return hasId || (hasMultipleFields && hasEntityFields);
	}
	
	private inferEntityType(obj: any, path: string[]): string {
		// Try to infer type from object properties (e.g., __typename)
		if (obj.__typename) return this.sanitizeTableName(obj.__typename);
		if (obj.type && typeof obj.type === 'string' && !['edges', 'node'].includes(obj.type.toLowerCase())) {
			return this.sanitizeTableName(obj.type);
		}
		
		// Special Open Targets patterns
		if (obj.ensemblId) return 'target';
		if (obj.efoId) return 'disease';
		if (obj.chemblId) return 'drug';
		if (obj.approvedSymbol) return 'target';
		
		// Infer from path context, attempting to singularize
		if (path.length > 0) {
			let lastName = path[path.length - 1];

			// Handle GraphQL patterns
			if (lastName === 'node' && path.length > 1) {
				lastName = path[path.length - 2];
				if (lastName === 'edges' && path.length > 2) {
					lastName = path[path.length - 3];
				}
			} else if (lastName === 'edges' && path.length > 1) {
				lastName = path[path.length - 2];
			} else if (lastName === 'rows' && path.length > 1) {
				lastName = path[path.length - 2];
			}
			
			// Attempt to singularize common plural forms
			const sanitized = this.sanitizeTableName(lastName);
			if (sanitized.endsWith('ies')) {
				return sanitized.slice(0, -3) + 'y';
			} else if (sanitized.endsWith('s') && !sanitized.endsWith('ss') && sanitized.length > 1) {
				const potentialSingular = sanitized.slice(0, -1);
				if (potentialSingular.length > 1) return potentialSingular;
			}
			return sanitized;
		}
		
		// Fallback naming if no other inference is possible
		return 'entity_' + Math.random().toString(36).substr(2, 9);
	}
	
	private recordRelationship(fromTable: string, toTable: string): void {
		if (fromTable === toTable) return; // Avoid self-relationships
		
		const relationshipKey = `${fromTable}_${toTable}`;
		const reverseKey = `${toTable}_${fromTable}`;
		
		const fromRelationships = this.entityRelationships.get(fromTable) || new Set();
		const toRelationships = this.entityRelationships.get(toTable) || new Set();
		
		// Only record if not already recorded in either direction
		if (!fromRelationships.has(toTable) && !toRelationships.has(fromTable)) {
			fromRelationships.add(toTable);
			this.entityRelationships.set(fromTable, fromRelationships);
		}
	}
	
	private createSchemasFromEntities(schemas: Record<string, TableSchema>): void {
		// Create main entity tables
		for (const [entityType, entities] of this.discoveredEntities.entries()) {
			if (entities.length === 0) continue;
			
			const columnTypes: Record<string, Set<string>> = {};
			const sampleData: any[] = [];
			
			entities.forEach((entity, index) => {
				if (index < 3) {
					sampleData.push(this.extractEntityFields(entity, columnTypes, entityType));
				} else {
					this.extractEntityFields(entity, columnTypes, entityType);
				}
			});
			
			const columns = this.resolveColumnTypes(columnTypes);
			this.ensureIdColumn(columns);
			
			schemas[entityType] = {
				columns,
				sample_data: sampleData
			};
		}
		
		// Create junction tables for many-to-many relationships
		this.createJunctionTableSchemas(schemas);
	}
	
	private extractEntityFields(obj: any, columnTypes: Record<string, Set<string>>, entityType: string): any {
		const rowData: any = {};
		
		if (!obj || typeof obj !== 'object') {
			this.addColumnType(columnTypes, 'value', this.getSQLiteType(obj));
			return { value: obj };
		}
		
		for (const [key, value] of Object.entries(obj)) {
			const columnName = this.sanitizeColumnName(key);
			
			if (Array.isArray(value)) {
				// Check if this array contains entities that should be related
				if (value.length > 0 && this.isEntity(value[0])) {
					// This will be handled as a relationship via junction table, skip for now
					continue;
				} else {
					// Store as JSON for analysis
					this.addColumnType(columnTypes, columnName + '_json', 'TEXT');
					rowData[columnName + '_json'] = JSON.stringify(value);
				}
			} else if (value && typeof value === 'object') {
				if (this.isEntity(value)) {
					// This is a related entity - create foreign key
					const foreignKeyColumn = columnName + '_id';
					this.addColumnType(columnTypes, foreignKeyColumn, 'INTEGER');
					rowData[foreignKeyColumn] = (value as any).id || null;
				} else {
					// Complex object that's not an entity
					if (this.hasScalarFields(value)) {
						// Flatten simple fields with prefixed names
						for (const [subKey, subValue] of Object.entries(value)) {
							if (!Array.isArray(subValue) && typeof subValue !== 'object') {
								const prefixedColumn = columnName + '_' + this.sanitizeColumnName(subKey);
								this.addColumnType(columnTypes, prefixedColumn, this.getSQLiteType(subValue));
								rowData[prefixedColumn] = typeof subValue === 'boolean' ? (subValue ? 1 : 0) : subValue;
							}
						}
					} else {
						// Store complex object as JSON
						this.addColumnType(columnTypes, columnName + '_json', 'TEXT');
						rowData[columnName + '_json'] = JSON.stringify(value);
					}
				}
			} else {
				// Scalar values
				this.addColumnType(columnTypes, columnName, this.getSQLiteType(value));
				rowData[columnName] = typeof value === 'boolean' ? (value ? 1 : 0) : value;
			}
		}
		
		return rowData;
	}
	
	private hasScalarFields(obj: any): boolean {
		if (!obj || typeof obj !== 'object') return false;
		return Object.values(obj).some(value => 
			typeof value !== 'object' || value === null
		);
	}
	
	private createJunctionTableSchemas(schemas: Record<string, TableSchema>): void {
		const junctionTables = new Set<string>();
		
		for (const [fromTable, relatedTables] of this.entityRelationships.entries()) {
			for (const toTable of relatedTables) {
				// Create a consistent junction table name (alphabetical order to avoid duplicates)
				const junctionName = [fromTable, toTable].sort().join('_');
				
				if (!junctionTables.has(junctionName)) {
					junctionTables.add(junctionName);
					
					schemas[junctionName] = {
						columns: {
							id: 'INTEGER PRIMARY KEY AUTOINCREMENT',
							[`${fromTable}_id`]: 'INTEGER',
							[`${toTable}_id`]: 'INTEGER'
						},
						sample_data: []
					};
				}
			}
		}
	}
	
	private createSchemaFromPrimitiveOrSimpleArray(data: any, tableName: string): TableSchema {
		const columnTypes: Record<string, Set<string>> = {};
		const sampleData: any[] = [];
		
		if (Array.isArray(data)) {
			data.slice(0,3).forEach(item => {
				const row = this.extractSimpleFields(item, columnTypes);
				sampleData.push(row);
			});
			if (data.length > 3) {
				data.slice(3).forEach(item => this.extractSimpleFields(item, columnTypes));
			}
		} else { // Scalar data
			const row = this.extractSimpleFields(data, columnTypes);
			sampleData.push(row);
		}
		
		const columns = this.resolveColumnTypes(columnTypes);
		if (!Object.keys(columns).includes('id') && !Object.keys(columns).includes('value')) {
			const colNames = Object.keys(columns);
			if(colNames.length === 1 && colNames[0] !== 'value'){
				columns['value'] = columns[colNames[0]];
				delete columns[colNames[0]];
				sampleData.forEach(s => { s['value'] = s[colNames[0]]; delete s[colNames[0]]; });
			}
		}
		if (Object.keys(columns).length === 0 && data === null) {
		    columns['value'] = 'TEXT';
		}

		return { columns, sample_data: sampleData };
	}

	private createSchemaFromObject(obj: any, tableName: string): TableSchema {
		const columnTypes: Record<string, Set<string>> = {};
		const rowData = this.extractSimpleFields(obj, columnTypes);
		const columns = this.resolveColumnTypes(columnTypes);
		return { columns, sample_data: [rowData] };
	}

	private extractSimpleFields(obj: any, columnTypes: Record<string, Set<string>>): any {
		const rowData: any = {};
		
		if (obj === null || typeof obj !== 'object') {
			this.addColumnType(columnTypes, 'value', this.getSQLiteType(obj));
			return { value: obj };
		}
		
		if (Array.isArray(obj)) {
			this.addColumnType(columnTypes, 'array_data_json', 'TEXT');
			return { array_data_json: JSON.stringify(obj) };
		}

		for (const [key, value] of Object.entries(obj)) {
			const columnName = this.sanitizeColumnName(key);
			if (value === null || typeof value !== 'object') {
				this.addColumnType(columnTypes, columnName, this.getSQLiteType(value));
				rowData[columnName] = typeof value === 'boolean' ? (value ? 1 : 0) : value;
			} else {
				this.addColumnType(columnTypes, columnName + '_json', 'TEXT');
				rowData[columnName + '_json'] = JSON.stringify(value);
			}
		}
		return rowData;
	}
	
	private addColumnType(columnTypes: Record<string, Set<string>>, column: string, type: string): void {
		if (!columnTypes[column]) columnTypes[column] = new Set();
		columnTypes[column].add(type);
	}
	
	private resolveColumnTypes(columnTypes: Record<string, Set<string>>): Record<string, string> {
		const columns: Record<string, string> = {};
		
		for (const [columnName, types] of Object.entries(columnTypes)) {
			if (types.size === 1) {
				columns[columnName] = Array.from(types)[0];
			} else {
				// Mixed types - prefer TEXT > REAL > INTEGER
				columns[columnName] = types.has('TEXT') ? 'TEXT' : types.has('REAL') ? 'REAL' : 'INTEGER';
			}
		}
		
		return columns;
	}
	
	private ensureIdColumn(columns: Record<string, string>): void {
		if (!columns.id) {
			columns.id = "INTEGER PRIMARY KEY AUTOINCREMENT";
		} else if (columns.id === "INTEGER") {
			columns.id = "INTEGER PRIMARY KEY";
		}
	}
	
	private getSQLiteType(value: any): string {
		if (value === null || value === undefined) return "TEXT";
		switch (typeof value) {
			case 'number': return Number.isInteger(value) ? "INTEGER" : "REAL";
			case 'boolean': return "INTEGER";
			case 'string': return "TEXT";
			default: return "TEXT";
		}
	}
	
	private sanitizeTableName(name: string): string {
		if (!name || typeof name !== 'string') {
			return 'table_' + Math.random().toString(36).substr(2, 9);
		}
		
		let sanitized = name
			.replace(/[^a-zA-Z0-9_]/g, '_')
			.replace(/_{2,}/g, '_')  // Replace multiple underscores with single
			.replace(/^_|_$/g, '')  // Remove leading/trailing underscores
			.toLowerCase();
		
		// Ensure it doesn't start with a number
		if (/^[0-9]/.test(sanitized)) {
			sanitized = 'table_' + sanitized;
		}
		
		// Ensure it's not empty and not a SQL keyword
		if (!sanitized || sanitized.length === 0) {
			sanitized = 'table_' + Math.random().toString(36).substr(2, 9);
		}
		
		// Handle SQL reserved words
		const reservedWords = ['table', 'index', 'view', 'column', 'primary', 'key', 'foreign', 'constraint'];
		if (reservedWords.includes(sanitized)) {
			sanitized = sanitized + '_table';
		}
		
		return sanitized;
	}
	
	private sanitizeColumnName(name: string): string {
		if (!name || typeof name !== 'string') {
			return 'column_' + Math.random().toString(36).substr(2, 9);
		}
		
		// Convert camelCase to snake_case
		let snakeCase = name
			.replace(/([A-Z])/g, '_$1')
			.toLowerCase()
			.replace(/[^a-zA-Z0-9_]/g, '_')
			.replace(/_{2,}/g, '_')  // Replace multiple underscores with single
			.replace(/^_|_$/g, ''); // Remove leading/trailing underscores
		
		// Ensure it doesn't start with a number
		if (/^[0-9]/.test(snakeCase)) {
			snakeCase = 'col_' + snakeCase;
		}
		
		// Ensure it's not empty
		if (!snakeCase || snakeCase.length === 0) {
			snakeCase = 'column_' + Math.random().toString(36).substr(2, 9);
		}
		
		// Handle Open Targets-specific naming patterns
		const openTargetsTerms: Record<string, string> = {
			'ensemblid': 'ensembl_id',
			'efoid': 'efo_id', 
			'chemblid': 'chembl_id',
			'approvedsymbol': 'approved_symbol',
			'approvedname': 'approved_name',
			'geneticconstraint': 'genetic_constraint',
			'mechanismsofaction': 'mechanisms_of_action',
			'therapeuticareas': 'therapeutic_areas',
			'pharmacovigilance': 'pharmacovigilance'
		};
		
		const result = openTargetsTerms[snakeCase] || snakeCase;
		
		// Handle SQL reserved words
		const reservedWords = ['table', 'index', 'view', 'column', 'primary', 'key', 'foreign', 'constraint', 'order', 'group', 'select', 'from', 'where'];
		if (reservedWords.includes(result)) {
			return result + '_col';
		}
		
		return result;
	}
} 
--------------------------------------------------------------------------------
END OF FILE: src/lib/SchemaInferenceEngine.ts
--------------------------------------------------------------------------------


================================================================================
FILE: src/lib/SchemaParser.ts
================================================================================

import { GraphQLSchemaInfo, GraphQLTypeInfo, GraphQLFieldInfo, FieldChunkingRule } from "./ChunkingEngine.js";

export interface EntityRelationshipInfo {
	fromType: string;
	toType: string;
	fieldName: string;
	cardinality: 'one-to-one' | 'one-to-many' | 'many-to-many';
	isEntityList: boolean;
}

export interface FieldExtractionRule {
	fieldName: string;
	typeName: string;
	shouldExtractEntities: boolean;
	targetEntityType?: string;
	isListField: boolean;
}

/**
 * Parses GraphQL schema files and extracts chunking-relevant information
 * Optimized for Open Targets Platform API patterns
 */
export class SchemaParser {
	private schemaInfo?: GraphQLSchemaInfo;
	private extractionRules: FieldExtractionRule[] = [];
	private relationships: EntityRelationshipInfo[] = [];

	/**
	 * Parse a GraphQL schema string and extract type information
	 */
	static parseSchema(schemaContent: string): GraphQLSchemaInfo {
		const types: Record<string, GraphQLTypeInfo> = {};
		const relationships: Array<{
			fromType: string;
			toType: string;
			fieldName: string;
			cardinality: string;
		}> = [];

		// Parse types using regex patterns
		const typeMatches = schemaContent.matchAll(/type\s+(\w+)(?:\s+implements\s+[\w\s&]+)?\s*\{([^}]+(?:\}[^}]*)*)\}/g);
		
		for (const match of typeMatches) {
			const typeName = match[1];
			const typeBody = match[2];
			
			if (this.shouldSkipType(typeName)) {
				continue;
			}

			const fields = this.parseFields(typeBody, typeName, relationships);
			
			types[typeName] = {
				name: typeName,
				kind: 'OBJECT',
				fields,
				description: this.extractDescription(match[0])
			};
		}

		return { types, relationships };
	}

	/**
	 * Generate chunking rules based on Open Targets schema patterns
	 */
	static generateChunkingRulesFromSchema(schemaInfo: GraphQLSchemaInfo): FieldChunkingRule[] {
		const rules: FieldChunkingRule[] = [
			// Base rules that apply to all types
			{ fieldName: 'id', typeName: '*', chunkThreshold: Infinity, priority: 'never', reason: 'ID fields should never be chunked' },
			{ fieldName: 'ensemblId', typeName: '*', chunkThreshold: Infinity, priority: 'never', reason: 'Ensembl ID fields should never be chunked' },
			{ fieldName: 'efoId', typeName: '*', chunkThreshold: Infinity, priority: 'never', reason: 'EFO ID fields should never be chunked' },
			{ fieldName: 'chemblId', typeName: '*', chunkThreshold: Infinity, priority: 'never', reason: 'ChEMBL ID fields should never be chunked' },
		];

		// Analyze schema types for large content fields
		for (const [typeName, typeInfo] of Object.entries(schemaInfo.types)) {
			for (const [fieldName, fieldInfo] of Object.entries(typeInfo.fields)) {
				const rule = this.generateFieldRule(typeName, fieldName, fieldInfo);
				if (rule) {
					rules.push(rule);
				}
			}
		}

		// Add Open Targets-specific knowledge
		rules.push(
			// Known large text fields from Open Targets API
			{ fieldName: 'description', typeName: 'Target', chunkThreshold: 2048, priority: 'always', reason: 'Target descriptions are typically very long' },
			{ fieldName: 'description', typeName: 'Disease', chunkThreshold: 2048, priority: 'always', reason: 'Disease descriptions can be extensive' },
			{ fieldName: 'description', typeName: 'Drug', chunkThreshold: 2048, priority: 'always', reason: 'Drug descriptions can be extensive' },
			{ fieldName: 'synonyms', typeName: '*', chunkThreshold: 1024, priority: 'always', reason: 'Synonym arrays are often extensive' },
			
			// Tractability and constraint data
			{ fieldName: 'tractability', typeName: 'Target', chunkThreshold: 4096, priority: 'size-based', reason: 'Tractability data contains extensive nested information' },
			{ fieldName: 'geneticConstraint', typeName: 'Target', chunkThreshold: 2048, priority: 'size-based', reason: 'Genetic constraint data can be detailed' },
			{ fieldName: 'safety', typeName: 'Target', chunkThreshold: 4096, priority: 'size-based', reason: 'Safety information can be extensive' },
			
			// Association and evidence data - these can be huge
			{ fieldName: 'associatedTargets', typeName: '*', chunkThreshold: 8192, priority: 'size-based', reason: 'Target association connections can be extensive' },
			{ fieldName: 'associatedDiseases', typeName: '*', chunkThreshold: 8192, priority: 'size-based', reason: 'Disease association connections can be extensive' },
			{ fieldName: 'evidences', typeName: '*', chunkThreshold: 8192, priority: 'size-based', reason: 'Evidence connections can contain many detailed evidence objects' },
			{ fieldName: 'studies', typeName: '*', chunkThreshold: 6144, priority: 'size-based', reason: 'Study connections can be extensive' },
			
			// Pharmacovigilance and drug data
			{ fieldName: 'pharmacovigilance', typeName: 'Drug', chunkThreshold: 8192, priority: 'size-based', reason: 'Pharmacovigilance data can be very large' },
			{ fieldName: 'mechanismsOfAction', typeName: 'Drug', chunkThreshold: 4096, priority: 'size-based', reason: 'Mechanism of action data can be extensive' },
			{ fieldName: 'indications', typeName: 'Drug', chunkThreshold: 4096, priority: 'size-based', reason: 'Drug indications can be numerous' },
			
			// Ontology and classification data
			{ fieldName: 'ontology', typeName: 'Disease', chunkThreshold: 4096, priority: 'size-based', reason: 'Ontology data can contain extensive hierarchical information' },
			{ fieldName: 'therapeuticAreas', typeName: 'Disease', chunkThreshold: 2048, priority: 'size-based', reason: 'Therapeutic area data can be extensive' },
			
			// Expression and interaction data
			{ fieldName: 'expressions', typeName: 'Target', chunkThreshold: 6144, priority: 'size-based', reason: 'Expression data can be extensive across tissues' },
			{ fieldName: 'interactions', typeName: 'Target', chunkThreshold: 6144, priority: 'size-based', reason: 'Interaction data can be extensive' },
			{ fieldName: 'pathways', typeName: 'Target', chunkThreshold: 4096, priority: 'size-based', reason: 'Pathway data can be extensive' },
			
			// Conservative chunking for names and identifiers
			{ fieldName: 'approvedName', typeName: '*', chunkThreshold: 512, priority: 'size-based', reason: 'Approved names are usually short but can be long' },
			{ fieldName: 'approvedSymbol', typeName: '*', chunkThreshold: 256, priority: 'size-based', reason: 'Symbols are usually short' },
			{ fieldName: 'name', typeName: '*', chunkThreshold: 512, priority: 'size-based', reason: 'Names are usually short but can be long' },
		);

		return rules;
	}

	/**
	 * Identify the most critical types for chunking optimization in Open Targets
	 */
	static identifyHighValueTypes(schemaInfo: GraphQLSchemaInfo): Array<{
		typeName: string;
		reason: string;
		largeFields: string[];
		estimatedSize: 'small' | 'medium' | 'large' | 'very_large';
	}> {
		const highValueTypes = [];

		// Core entity types that typically have large content in Open Targets
		const coreTypes = ['Target', 'Disease', 'Drug', 'Evidence', 'Study', 'Association'];
		
		for (const typeName of coreTypes) {
			const typeInfo = schemaInfo.types[typeName];
			if (typeInfo) {
				const largeFields = Object.keys(typeInfo.fields).filter(fieldName => 
					this.isLikelyLargeField(fieldName, typeInfo.fields[fieldName])
				);
				
				highValueTypes.push({
					typeName,
					reason: `Core Open Targets entity with ${largeFields.length} potentially large fields`,
					largeFields,
					estimatedSize: this.estimateTypeSize(typeInfo)
				});
			}
		}

		return highValueTypes;
	}

	// Private helper methods

	private static shouldSkipType(typeName: string): boolean {
		// Skip GraphQL built-in types, input types, and connection/edge types
		const skipPatterns = [
			/^__/,  // Introspection types
			/Input$/,  // Input types
			/Payload$/,  // Mutation payloads
			/Connection$/,  // GraphQL connections
			/Edge$/,  // GraphQL edges
			/^(String|Int|Float|Boolean|ID)$/,  // Scalars
		];
		
		return skipPatterns.some(pattern => pattern.test(typeName));
	}

	private static parseFields(typeBody: string, typeName: string, relationships: any[]): Record<string, GraphQLFieldInfo> {
		const fields: Record<string, GraphQLFieldInfo> = {};
		
		// Match field definitions - handle both simple and complex cases
		const fieldMatches = typeBody.matchAll(/^\s*([a-zA-Z]\w*)\s*(?:\([^)]*\))?\s*:\s*([^!\n]+[!]?)/gm);
		
		for (const match of fieldMatches) {
			const fieldName = match[1];
			const fieldType = match[2].trim();
			
			// Skip comment-like patterns
			if (fieldName.includes('"""') || fieldType.includes('"""')) {
				continue;
			}

			const fieldInfo = this.parseFieldType(fieldType);
			fields[fieldName] = {
				name: fieldName,
				...fieldInfo
			};

			// Track relationships
			if (this.isRelationshipField(fieldInfo, typeName)) {
				relationships.push({
					fromType: typeName,
					toType: this.extractRelatedType(fieldInfo.type),
					fieldName: fieldName,
					cardinality: fieldInfo.isList ? 'one-to-many' : 'one-to-one'
				});
			}
		}

		return fields;
	}

	private static parseFieldType(typeString: string): Omit<GraphQLFieldInfo, 'name'> {
		let type = typeString.trim();
		let isList = false;
		let isNullable = true;

		// Handle list types
		if (type.startsWith('[') && type.endsWith(']')) {
			isList = true;
			type = type.slice(1, -1);
		}

		// Handle non-null types
		if (type.endsWith('!')) {
			isNullable = false;
			type = type.slice(0, -1);
		}

		// Handle nested non-null in lists
		if (isList && type.endsWith('!')) {
			type = type.slice(0, -1);
		}

		return {
			type: type.trim(),
			isList,
			isNullable
		};
	}

	private static isRelationshipField(fieldInfo: Omit<GraphQLFieldInfo, 'name'>, typeName: string): boolean {
		// Skip scalar types
		const scalarTypes = ['String', 'Int', 'Float', 'Boolean', 'ID', 'JSON', 'ISO8601DateTime'];
		if (scalarTypes.includes(fieldInfo.type)) {
			return false;
		}

		// Skip enum-like types (they usually end with specific patterns)
		const enumPatterns = [/Level$/, /Type$/, /Status$/, /Direction$/, /Category$/];
		if (enumPatterns.some(pattern => pattern.test(fieldInfo.type))) {
			return false;
		}

		return true;
	}

	private static extractRelatedType(typeString: string): string {
		// Remove any remaining brackets or exclamation marks
		return typeString.replace(/[[\]!]/g, '');
	}

	private static extractDescription(typeDefinition: string): string | undefined {
		const descMatch = typeDefinition.match(/"""([^"]+)"""/);
		return descMatch ? descMatch[1].trim() : undefined;
	}

	private static generateFieldRule(typeName: string, fieldName: string, fieldInfo: GraphQLFieldInfo): FieldChunkingRule | null {
		// Generate rules for likely large content fields
		if (this.isLikelyLargeField(fieldName, fieldInfo)) {
			if (fieldInfo.type === 'String') {
				// Text fields that are likely to be large
				const textFieldThresholds: Record<string, number> = {
					'description': 2048,
					'summary': 1024,
					'synonyms': 1024,
					'approvedName': 512,
					'name': 512
				};

				const threshold = textFieldThresholds[fieldName] || 512;
				
				return {
					fieldName,
					typeName,
					chunkThreshold: threshold,
					priority: 'size-based',
					reason: `String field '${fieldName}' on type '${typeName}' likely contains large text content`
				};
			} else if (fieldInfo.type === 'JSON') {
				// JSON fields can be very large
				return {
					fieldName,
					typeName,
					chunkThreshold: 4096,
					priority: 'size-based',
					reason: `JSON field '${fieldName}' on type '${typeName}' can contain large structured data`
				};
			} else if (fieldInfo.isList) {
				// List fields can accumulate to large sizes
				return {
					fieldName,
					typeName,
					chunkThreshold: 8192,
					priority: 'size-based',
					reason: `List field '${fieldName}' on type '${typeName}' can contain many items`
				};
			}
		}

		return null;
	}

	private static isLikelyLargeField(fieldName: string, fieldInfo: GraphQLFieldInfo): boolean {
		const largeContentIndicators = [
			'description', 'summary', 'synonyms', 'evidence', 'associations',
			'tractability', 'constraint', 'safety', 'pharmacovigilance', 
			'mechanisms', 'indications', 'ontology', 'expressions', 'interactions',
			'pathways', 'therapeuticAreas', 'studies', 'targets', 'diseases'
		];
		
		// Check field name
		if (largeContentIndicators.some(indicator => 
			fieldName.toLowerCase().includes(indicator)
		)) {
			return true;
		}

		// Check if it's a JSON field (these can be large)
		if (fieldInfo.type === 'JSON') {
			return true;
		}

		// Check if it's a connection field (GraphQL pagination)
		if (fieldInfo.type.includes('Connection')) {
			return true;
		}

		// Check if it's a list that could accumulate size
		if (fieldInfo.isList && !fieldName.includes('Id')) {
			return true;
		}

		return false;
	}

	private static estimateTypeSize(typeInfo: GraphQLTypeInfo): 'small' | 'medium' | 'large' | 'very_large' {
		const fieldCount = Object.keys(typeInfo.fields).length;
		const largeFieldCount = Object.entries(typeInfo.fields).filter(([name, field]) => 
			this.isLikelyLargeField(name, field)
		).length;

		if (largeFieldCount >= 5 || fieldCount >= 50) {
			return 'very_large';
		} else if (largeFieldCount >= 3 || fieldCount >= 30) {
			return 'large';
		} else if (largeFieldCount >= 1 || fieldCount >= 15) {
			return 'medium';
		} else {
			return 'small';
		}
	}

	/**
	 * Parse the GraphQL schema file and extract structure information
	 */
	async parseSchemaFromFile(schemaPath: string): Promise<GraphQLSchemaInfo> {
		// For Cloudflare Workers environment, we'd need to pass content differently
		// This is a placeholder - in practice, schema content would be loaded at build time
		// or passed as a parameter
		throw new Error('File system access not available in Workers environment. Use parseSchemaContent() instead.');
	}

	/**
	 * Parse GraphQL schema content and extract type/relationship information
	 */
	parseSchemaContent(schemaContent: string): GraphQLSchemaInfo {
		const types: Record<string, GraphQLTypeInfo> = {};
		const relationships: Array<{fromType: string, toType: string, fieldName: string, cardinality: string}> = [];

		// Split schema into type definitions
		const typeBlocks = this.extractTypeBlocks(schemaContent);

		for (const block of typeBlocks) {
			const typeInfo = this.parseTypeBlock(block);
			if (typeInfo) {
				types[typeInfo.name] = typeInfo;
				
				// Extract relationships from this type
				const typeRelationships = this.extractRelationshipsFromType(typeInfo);
				relationships.push(...typeRelationships);
			}
		}

		this.schemaInfo = { types, relationships };
		this.generateExtractionRules();
		
		return this.schemaInfo;
	}

	/**
	 * Get extraction rules for intelligent entity processing
	 */
	getExtractionRules(): FieldExtractionRule[] {
		return this.extractionRules;
	}

	/**
	 * Get relationship information
	 */
	getRelationships(): EntityRelationshipInfo[] {
		return this.relationships;
	}

	/**
	 * Check if a field should have its entities extracted vs stored as JSON
	 */
	shouldExtractEntities(typeName: string, fieldName: string): {
		extract: boolean;
		targetType?: string;
		isListField: boolean;
	} {
		const rule = this.extractionRules.find(r => 
			(r.typeName === typeName || r.typeName === '*') && r.fieldName === fieldName
		);

		if (rule) {
			return {
				extract: rule.shouldExtractEntities,
				targetType: rule.targetEntityType,
				isListField: rule.isListField
			};
		}

		// Default: extract if field name suggests entities
		const entityFieldPatterns = [
			/.*targets?$/i,
			/.*diseases?$/i,
			/.*drugs?$/i,
			/.*evidences?$/i,
			/.*studies?$/i,
			/.*associations?$/i,
			/.*variants?$/i,
			/.*genes?$/i
		];

		const suggestsEntities = entityFieldPatterns.some(pattern => pattern.test(fieldName));
		
		return {
			extract: suggestsEntities,
			targetType: this.inferTargetType(fieldName),
			isListField: fieldName.endsWith('s') // Simple heuristic
		};
	}

	/**
	 * Extract type definition blocks from schema content
	 */
	private extractTypeBlocks(schemaContent: string): string[] {
		const typeBlocks: string[] = [];
		const lines = schemaContent.split('\n');
		
		let currentBlock = '';
		let inTypeDefinition = false;
		let braceCount = 0;

		for (const line of lines) {
			const trimmedLine = line.trim();
			
			// Skip comments and empty lines when not in a type
			if (!inTypeDefinition && (trimmedLine.startsWith('#') || trimmedLine === '')) {
				continue;
			}

			// Check for type definition start
			if (trimmedLine.match(/^(type|interface|enum|input)\s+\w+/)) {
				// Save previous block if exists
				if (currentBlock.trim()) {
					typeBlocks.push(currentBlock.trim());
				}
				currentBlock = line + '\n';
				inTypeDefinition = true;
				braceCount = 0;
			} else if (inTypeDefinition) {
				currentBlock += line + '\n';
				
				// Count braces to determine when type definition ends
				braceCount += (line.match(/\{/g) || []).length;
				braceCount -= (line.match(/\}/g) || []).length;
				
				if (braceCount === 0 && trimmedLine.includes('}')) {
					typeBlocks.push(currentBlock.trim());
					currentBlock = '';
					inTypeDefinition = false;
				}
			}
		}

		// Add final block if exists
		if (currentBlock.trim()) {
			typeBlocks.push(currentBlock.trim());
		}

		return typeBlocks;
	}

	/**
	 * Parse individual type block into TypeInfo
	 */
	private parseTypeBlock(block: string): GraphQLTypeInfo | null {
		const lines = block.split('\n');
		const firstLine = lines[0].trim();
		
		// Extract type name and kind
		const typeMatch = firstLine.match(/^(type|interface|enum|input)\s+(\w+)/);
		if (!typeMatch) return null;

		const [, kind, name] = typeMatch;
		const fields: Record<string, GraphQLFieldInfo> = {};

		// Parse fields (skip first and last lines which are type declaration and closing brace)
		for (let i = 1; i < lines.length - 1; i++) {
			const line = lines[i].trim();
			if (line && !line.startsWith('#') && !line.startsWith('"""')) {
				const fieldInfo = this.parseFieldLine(line);
				if (fieldInfo) {
					fields[fieldInfo.name] = fieldInfo;
				}
			}
		}

		return {
			name,
			kind: kind.toUpperCase() as 'OBJECT' | 'SCALAR' | 'ENUM' | 'INTERFACE',
			fields,
			description: this.extractDescription(block)
		};
	}

	/**
	 * Parse individual field line
	 */
	private parseFieldLine(line: string): GraphQLFieldInfo | null {
		// Match field patterns like: fieldName: Type, fieldName: [Type], fieldName(args): Type
		const fieldMatch = line.match(/^(\w+)(?:\([^)]*\))?:\s*(\[?)([^!\[\]]+)(!?)\]?(!?)/);
		if (!fieldMatch) return null;

		const [, name, listStart, type, typeRequired, listRequired] = fieldMatch;
		
		return {
			name,
			type: type.trim(),
			isList: !!listStart,
			isNullable: !typeRequired && !listRequired,
			description: undefined // Could be enhanced to extract field descriptions
		};
	}

	/**
	 * Extract relationships from a type definition
	 */
	private extractRelationshipsFromType(typeInfo: GraphQLTypeInfo): Array<{fromType: string, toType: string, fieldName: string, cardinality: string}> {
		const relationships = [];

		for (const [fieldName, fieldInfo] of Object.entries(typeInfo.fields)) {
			// Check if this field references another entity type
			if (this.isEntityType(fieldInfo.type)) {
				const cardinality = fieldInfo.isList ? 'one-to-many' : 'one-to-one';
				relationships.push({
					fromType: typeInfo.name,
					toType: fieldInfo.type,
					fieldName,
					cardinality
				});
			}
		}

		return relationships;
	}

	/**
	 * Check if a type name represents an entity (vs scalar)
	 */
	private isEntityType(typeName: string): boolean {
		const scalarTypes = ['String', 'Int', 'Float', 'Boolean', 'ID', 'DateTime', 'ISO8601DateTime'];
		return !scalarTypes.includes(typeName) && typeName[0] === typeName[0].toUpperCase();
	}

	/**
	 * Generate field extraction rules based on schema analysis
	 */
	private generateExtractionRules(): void {
		if (!this.schemaInfo) return;

		this.extractionRules = [];

		for (const [typeName, typeInfo] of Object.entries(this.schemaInfo.types)) {
			for (const [fieldName, fieldInfo] of Object.entries(typeInfo.fields)) {
				// Rule: Extract entities from list fields that reference entity types
				if (fieldInfo.isList && this.isEntityType(fieldInfo.type)) {
					this.extractionRules.push({
						fieldName,
						typeName,
						shouldExtractEntities: true,
						targetEntityType: fieldInfo.type,
						isListField: true
					});
				}
				// Rule: Extract entities from single entity reference fields
				else if (!fieldInfo.isList && this.isEntityType(fieldInfo.type)) {
					this.extractionRules.push({
						fieldName,
						typeName,
						shouldExtractEntities: true,
						targetEntityType: fieldInfo.type,
						isListField: false
					});
				}
				// Rule: Don't extract from scalar fields
				else {
					this.extractionRules.push({
						fieldName,
						typeName,
						shouldExtractEntities: false,
						isListField: fieldInfo.isList
					});
				}
			}
		}

		// Add global rules for common patterns
		this.extractionRules.push(
			{ fieldName: 'id', typeName: '*', shouldExtractEntities: false, isListField: false },
			{ fieldName: 'ensemblId', typeName: '*', shouldExtractEntities: false, isListField: false },
			{ fieldName: 'efoId', typeName: '*', shouldExtractEntities: false, isListField: false },
			{ fieldName: 'chemblId', typeName: '*', shouldExtractEntities: false, isListField: false },
			{ fieldName: 'name', typeName: '*', shouldExtractEntities: false, isListField: false },
			{ fieldName: 'description', typeName: '*', shouldExtractEntities: false, isListField: false }
		);
	}

	/**
	 * Infer target entity type from field name
	 */
	private inferTargetType(fieldName: string): string {
		// Remove plural 's' and capitalize
		const singular = fieldName.endsWith('s') ? fieldName.slice(0, -1) : fieldName;
		return singular.charAt(0).toUpperCase() + singular.slice(1);
	}

	/**
	 * Extract description from type block
	 */
	private extractDescription(block: string): string | undefined {
		const descMatch = block.match(/"""([\s\S]*?)"""/);
		return descMatch ? descMatch[1].trim() : undefined;
	}
} 
--------------------------------------------------------------------------------
END OF FILE: src/lib/SchemaParser.ts
--------------------------------------------------------------------------------


================================================================================
FILE: src/lib/types.ts
================================================================================

export interface TableSchema {
    columns: Record<string, string>;
    sample_data: any[];
    relationships?: Record<string, RelationshipInfo>;
}

export interface RelationshipInfo {
    type: 'foreign_key' | 'junction_table';
    target_table: string;
    foreign_key_column?: string;
    junction_table_name?: string;
}

export interface ProcessingResult {
    success: boolean;
    message?: string;
    schemas?: Record<string, SchemaInfo>;
    table_count?: number;
    total_rows?: number;
    pagination?: PaginationInfo;
}

export interface SchemaInfo {
    columns: Record<string, string>;
    row_count: number;
    sample_data: any[];
    relationships?: Record<string, RelationshipInfo>;
}

export interface PaginationInfo {
    hasNextPage: boolean;
    hasPreviousPage: boolean;
    currentCount: number;
    totalCount: number | null;
    endCursor: string | null;
    startCursor: string | null;
    suggestion?: string;
}

export interface EntityContext {
    entityData?: any;
    parentTable?: string;
    parentKey?: string;
    relationshipType?: 'one_to_one' | 'one_to_many' | 'many_to_many';
} 
--------------------------------------------------------------------------------
END OF FILE: src/lib/types.ts
--------------------------------------------------------------------------------


================================================================================
FILE: src/index.ts
================================================================================

import { McpAgent } from "agents/mcp";
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { z } from "zod";
import { JsonToSqlDO } from "./do.js";

// ========================================
// API CONFIGURATION - Open Targets Platform
// ========================================
const API_CONFIG = {
	name: "OpenTargetsExplorer",
	version: "1.0.0",
	description: "MCP Server for querying Open Targets Platform GraphQL API and converting responses to queryable SQLite tables",
	
	// GraphQL API settings
	endpoint: 'https://api.platform.opentargets.org/api/v4/graphql',
	headers: {
		"Content-Type": "application/json",
		"User-Agent": "OpenTargetsMCP/1.0.0"
	},
	
	// Tool names and descriptions
	tools: {
		graphql: {
			name: "opentargets_graphql_query",
			description: "Executes GraphQL queries against the Open Targets Platform API, processes responses into SQLite tables, and returns metadata for subsequent SQL querying.\n\n**Two-Phase Workflow:**\n1. **Data Staging**: This tool executes your GraphQL query and automatically converts the response into normalized SQLite tables\n2. **SQL Analysis**: Use the returned data_access_id with the SQL query tool to perform complex analytical queries\n\n**Open Targets Platform Overview:**\nThe Open Targets Platform integrates evidence from genetics, genomics, transcriptomics, drugs, animal models and scientific literature to score and rank target-disease associations for drug discovery.\n\n**Key API Entities:**\n- **target**: Gene/protein targets (by Ensembl ID) - genetic constraints, tractability, expression\n- **disease**: Diseases/phenotypes (by EFO ID) - ontology, known drugs, clinical signs  \n- **drug**: Compounds/drugs (by ChEMBL ID) - mechanisms of action, indications\n- **associationsOnTheFly**: Target-disease associations with evidence scores\n- **search**: Cross-entity search functionality\n\nReturns a data_access_id for subsequent SQL querying of the staged data."
		},
		sql: {
			name: "opentargets_query_sql", 
			description: "Execute read-only SQL queries against staged Open Targets data. Use the data_access_id from opentargets_graphql_query to query the SQLite tables created from GraphQL responses."
		}
	}
};

// In-memory registry of staged datasets
const datasetRegistry = new Map<string, { created: string; table_count?: number; total_rows?: number }>();

// ========================================
// ENVIRONMENT INTERFACE
// ========================================
interface OpenTargetsEnv {
	MCP_HOST?: string;
	MCP_PORT?: string;
	JSON_TO_SQL_DO: DurableObjectNamespace;
}

// ========================================
// CORE MCP SERVER CLASS - Open Targets
// ========================================

export class OpenTargetsMCP extends McpAgent {
	server = new McpServer({
		name: API_CONFIG.name,
		version: API_CONFIG.version,
		description: API_CONFIG.description
	});

	async init() {
		// Tool #1: GraphQL to SQLite staging
		this.server.tool(
			API_CONFIG.tools.graphql.name,
			API_CONFIG.tools.graphql.description,
			{
				query: z.string().describe("GraphQL query string to execute against Open Targets Platform API"),
				variables: z.record(z.any()).optional().describe("Optional variables for the GraphQL query"),
			},
            async ({ query, variables }) => {
                try {
                    const graphqlResult = await this.executeGraphQLQuery(query, variables);

                    if (this.shouldBypassStaging(graphqlResult, query)) {
                        return {
                            content: [{
                                type: "text" as const,
                                text: JSON.stringify(graphqlResult, null, 2)
                            }]
                        };
                    }

                    const stagingResult = await this.stageDataInDurableObject(graphqlResult);
                    return {
                        content: [{
                            type: "text" as const,
                            text: JSON.stringify({
                                ...stagingResult,
                                usage_instructions: [
                                    `Use data_access_id="${stagingResult.data_access_id}" with the opentargets_query_sql tool to analyze the staged data`,
                                    "Example queries for Open Targets data:",
                                    "- Targets with high tractability: SELECT * FROM target WHERE json_extract(tractability_json, '$.score') > 0.8",
                                    "- Disease associations: SELECT * FROM disease_target_association ORDER BY score DESC LIMIT 10",
                                    "- Drug mechanisms: SELECT name, json_extract(mechanisms_json, '$[*].mechanismOfAction') FROM drug"
                                ]
                            }, null, 2)
                        }]
                    };

                } catch (error) {
                    return this.createErrorResponse("GraphQL execution failed", error);
                }
            }
        );

		// Tool #2: SQL querying against staged data
		this.server.tool(
			API_CONFIG.tools.sql.name,
			API_CONFIG.tools.sql.description,
			{
				data_access_id: z.string().describe("Data access ID from the GraphQL query tool"),
				sql: z.string().describe("SQL SELECT query to execute against the staged Open Targets data"),
				params: z.array(z.string()).optional().describe("Optional query parameters"),
			},
			async ({ data_access_id, sql }) => {
				try {
					const queryResult = await this.executeSQLQuery(data_access_id, sql);
					return { content: [{ type: "text" as const, text: JSON.stringify(queryResult, null, 2) }] };
				} catch (error) {
					return this.createErrorResponse("SQL execution failed", error);
				}
			}
		);
	}

	// ========================================
	// GRAPHQL CLIENT - Open Targets API
	// ========================================
    private async executeGraphQLQuery(query: string, variables?: Record<string, any>): Promise<any> {
        const headers = {
            ...API_CONFIG.headers
        };
		
		const body = { query, ...(variables && { variables }) };
		
		const response = await fetch(API_CONFIG.endpoint, {
			method: 'POST',
			headers,
			body: JSON.stringify(body),
		});
		
		if (!response.ok) {
			const errorText = await response.text();
			throw new Error(`Open Targets API HTTP ${response.status}: ${errorText}`);
		}
		
        const result = await response.json() as any;
        
        if (result.errors) {
            throw new Error(`GraphQL errors: ${JSON.stringify(result.errors)}`);
        }
        
        return result;
    }

    private isIntrospectionQuery(query: string): boolean {
        if (!query) return false;
        
        // Remove comments and normalize whitespace for analysis
        const normalizedQuery = query
            .replace(/\s*#.*$/gm, '') // Remove comments
            .replace(/\s+/g, ' ')     // Normalize whitespace
            .trim()
            .toLowerCase();
        
        // Check for common introspection patterns
        const introspectionPatterns = [
            '__schema',           // Schema introspection
            '__type',            // Type introspection
            '__typename',        // Typename introspection
            'introspectionquery', // Named introspection queries
            'getintrospectionquery'
        ];
        
        return introspectionPatterns.some(pattern => 
            normalizedQuery.includes(pattern)
        );
    }

    private shouldBypassStaging(result: any, originalQuery?: string): boolean {
        if (!result) return true;

        // Bypass if this was an introspection query
        if (originalQuery && this.isIntrospectionQuery(originalQuery)) {
            return true;
        }

        // Bypass if GraphQL reported errors
        if (result.errors) {
            return true;
        }

        // Check if response contains introspection-like data structure
        if (result.data) {
            // Common introspection response patterns
            if (result.data.__schema || result.data.__type) {
                return true;
            }
            
            // Check for schema metadata structures
            const hasSchemaMetadata = Object.values(result.data).some((value: any) => {
                if (value && typeof value === 'object') {
                    // Look for typical schema introspection fields
                    const keys = Object.keys(value);
                    const schemaFields = ['types', 'queryType', 'mutationType', 'subscriptionType', 'directives'];
                    const typeFields = ['name', 'kind', 'description', 'fields', 'interfaces', 'possibleTypes', 'enumValues', 'inputFields'];
                    
                    return schemaFields.some(field => keys.includes(field)) ||
                           typeFields.filter(field => keys.includes(field)).length >= 2;
                }
                return false;
            });
            
            if (hasSchemaMetadata) {
                return true;
            }
        }

        // Rough size check to avoid storing very small payloads
        try {
            if (JSON.stringify(result).length < 1500) {
                return true;
            }
        } catch {
            return true;
        }

        // Detect mostly empty data objects
        if (result.data) {
            const values = Object.values(result.data);
            const hasContent = values.some((v) => {
                if (v === null || v === undefined) return false;
                if (Array.isArray(v)) return v.length > 0;
                if (typeof v === "object") return Object.keys(v).length > 0;
                return true;
            });
            if (!hasContent) return true;
        }

        return false;
    }

	// ========================================
	// DURABLE OBJECT INTEGRATION
	// ========================================
	private async stageDataInDurableObject(graphqlResult: any): Promise<any> {
		const env = this.env as OpenTargetsEnv;
		if (!env?.JSON_TO_SQL_DO) {
			throw new Error("JSON_TO_SQL_DO binding not available");
		}
		
		const accessId = crypto.randomUUID();
		const doId = env.JSON_TO_SQL_DO.idFromName(accessId);
		const stub = env.JSON_TO_SQL_DO.get(doId);
		
		const response = await stub.fetch("http://do/process", {
			method: 'POST',
			headers: { 'Content-Type': 'application/json' },
			body: JSON.stringify(graphqlResult)
		});
		
		if (!response.ok) {
			const errorText = await response.text();
			throw new Error(`DO staging failed: ${errorText}`);
		}
		
        const processingResult = await response.json() as any;
        datasetRegistry.set(accessId, {
            created: new Date().toISOString(),
            table_count: processingResult.table_count,
            total_rows: processingResult.total_rows
        });
        return {
            data_access_id: accessId,
            processing_details: processingResult
        };
    }

    private async executeSQLQuery(dataAccessId: string, sql: string): Promise<any> {
		const env = this.env as OpenTargetsEnv;
		if (!env?.JSON_TO_SQL_DO) {
			throw new Error("JSON_TO_SQL_DO binding not available");
		}
		
		const doId = env.JSON_TO_SQL_DO.idFromName(dataAccessId);
		const stub = env.JSON_TO_SQL_DO.get(doId);
		
		// Use enhanced SQL execution that automatically resolves chunked content
		const response = await stub.fetch("http://do/query-enhanced", {
			method: 'POST',
			headers: { 'Content-Type': 'application/json' },
			body: JSON.stringify({ sql })
		});
		
		if (!response.ok) {
			const errorText = await response.text();
			throw new Error(`SQL execution failed: ${errorText}`);
		}
		
		return await response.json();
	}

    private async deleteDataset(dataAccessId: string): Promise<boolean> {
        const env = this.env as OpenTargetsEnv;
        if (!env?.JSON_TO_SQL_DO) {
            throw new Error("JSON_TO_SQL_DO binding not available");
        }

        const doId = env.JSON_TO_SQL_DO.idFromName(dataAccessId);
        const stub = env.JSON_TO_SQL_DO.get(doId);

        const response = await stub.fetch("http://do/delete", { method: 'DELETE' });

        return response.ok;
    }

	// ========================================
	// ERROR HANDLING - Reusable
	// ========================================
	private createErrorResponse(message: string, error: unknown) {
		return {
			content: [{
				type: "text" as const,
				text: JSON.stringify({
					success: false,
					error: message,
					details: error instanceof Error ? error.message : String(error)
				}, null, 2)
			}]
		};
	}
}

// ========================================
// CLOUDFLARE WORKERS BOILERPLATE
// ========================================
interface Env {
	MCP_HOST?: string;
	MCP_PORT?: string;
	JSON_TO_SQL_DO: DurableObjectNamespace;
}

interface ExecutionContext {
	waitUntil(promise: Promise<any>): void;
	passThroughOnException(): void;
}

export default {
    async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
        const url = new URL(request.url);

        if (url.pathname === "/sse" || url.pathname.startsWith("/sse/")) {
            // @ts-ignore - SSE transport handling
            return OpenTargetsMCP.serveSSE("/sse").fetch(request, env, ctx);
        }

        if (url.pathname === "/datasets" && request.method === "GET") {
            const list = Array.from(datasetRegistry.entries()).map(([id, info]) => ({
                data_access_id: id,
                ...info
            }));
            return new Response(JSON.stringify({ datasets: list }, null, 2), {
                headers: { "Content-Type": "application/json" }
            });
        }

        if (url.pathname.startsWith("/datasets/") && request.method === "DELETE") {
            const id = url.pathname.split("/")[2];
            if (!id || !datasetRegistry.has(id)) {
                return new Response(JSON.stringify({ error: "Dataset not found" }), {
                    status: 404,
                    headers: { "Content-Type": "application/json" }
                });
            }

            const doId = env.JSON_TO_SQL_DO.idFromName(id);
            const stub = env.JSON_TO_SQL_DO.get(doId);
            const resp = await stub.fetch("http://do/delete", { method: "DELETE" });
            if (resp.ok) {
                datasetRegistry.delete(id);
                return new Response(JSON.stringify({ success: true }), {
                    headers: { "Content-Type": "application/json" }
                });
            }

            const text = await resp.text();
            return new Response(JSON.stringify({ success: false, error: text }), {
                status: 500,
                headers: { "Content-Type": "application/json" }
            });
        }

        // Schema initialization endpoint
        if (url.pathname === "/initialize-schema" && request.method === "POST") {
            const globalDoId = env.JSON_TO_SQL_DO.idFromName("global-schema-config");
            const stub = env.JSON_TO_SQL_DO.get(globalDoId);
            const resp = await stub.fetch("http://do/initialize-schema", {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: await request.text()
            });
            return new Response(await resp.text(), {
                status: resp.status,
                headers: { "Content-Type": "application/json" }
            });
        }

        // Chunking stats endpoint
        if (url.pathname === "/chunking-stats" && request.method === "GET") {
            const globalDoId = env.JSON_TO_SQL_DO.idFromName("global-schema-config");
            const stub = env.JSON_TO_SQL_DO.get(globalDoId);
            const resp = await stub.fetch("http://do/chunking-stats");
            return new Response(await resp.text(), {
                status: resp.status,
                headers: { "Content-Type": "application/json" }
            });
        }

        // Chunking analysis endpoint
        if (url.pathname === "/chunking-analysis" && request.method === "GET") {
            const globalDoId = env.JSON_TO_SQL_DO.idFromName("global-schema-config");
            const stub = env.JSON_TO_SQL_DO.get(globalDoId);
            const resp = await stub.fetch("http://do/chunking-analysis");
            return new Response(await resp.text(), {
                status: resp.status,
                headers: { "Content-Type": "application/json" }
            });
        }

        return new Response(
            `${API_CONFIG.name} - Available on /sse endpoint`,
            { status: 404, headers: { "Content-Type": "text/plain" } }
        );
    },
};

export { OpenTargetsMCP as MyMCP };
export { JsonToSqlDO };

--------------------------------------------------------------------------------
END OF FILE: src/index.ts
--------------------------------------------------------------------------------


================================================================================
FILE: src/do.ts
================================================================================

import { DurableObject } from "cloudflare:workers";

import { SchemaInferenceEngine } from "./lib/SchemaInferenceEngine.js";
import { DataInsertionEngine } from "./lib/DataInsertionEngine.js";
import { PaginationAnalyzer } from "./lib/PaginationAnalyzer.js";
import { ChunkingEngine } from "./lib/ChunkingEngine.js";
import { SchemaParser } from "./lib/SchemaParser.js";
import { TableSchema, ProcessingResult, PaginationInfo } from "./lib/types.js";


// Main Durable Object class - optimized for Open Targets Platform data
export class JsonToSqlDO extends DurableObject {
	private chunkingEngine = new ChunkingEngine();

	constructor(ctx: DurableObjectState, env: any) {
		super(ctx, env);
	}

	async processAndStoreJson(jsonData: any): Promise<ProcessingResult> {
		try {
			let dataToProcess = jsonData?.data ? jsonData.data : jsonData;
			const paginationInfo = PaginationAnalyzer.extractInfo(dataToProcess); // Analyze from overall data structure

			const schemaEngine = new SchemaInferenceEngine();
			const schemas = schemaEngine.inferFromJSON(dataToProcess);
			
			// Create tables
			await this.createTables(schemas);
			
			// Insert data
			const dataInsertionEngine = new DataInsertionEngine();
			await dataInsertionEngine.insertData(dataToProcess, schemas, this.ctx.storage.sql);
			
			// Generate metadata
			const metadata = await this.generateMetadata(schemas);
			
			// Add pagination if available
			if (paginationInfo.hasNextPage) {
				metadata.pagination = paginationInfo;
			}
			
			return {
				success: true,
				message: "Open Targets data processed successfully",
				...metadata
			};
			
		} catch (error) {
			return {
				success: false,
				message: error instanceof Error ? error.message : "Processing failed"
			};
		}
	}

	async executeSql(sqlQuery: string): Promise<any> {
		try {
			// Enhanced security validation for analytical SQL
			const validationResult = this.validateAnalyticalSql(sqlQuery);
			if (!validationResult.isValid) {
				throw new Error(validationResult.error);
			}

			const result = this.ctx.storage.sql.exec(sqlQuery);
			const results = result.toArray();

			return {
				success: true,
				results,
				row_count: results.length,
				column_names: result.columnNames || [],
				query_type: validationResult.queryType
			};

		} catch (error) {
			return {
				success: false,
				error: error instanceof Error ? error.message : "SQL execution failed",
				query: sqlQuery
			};
		}
	}

	/**
	 * Enhanced SQL execution with automatic chunked content resolution
	 */
	async executeEnhancedSql(sqlQuery: string): Promise<any> {
		try {
			// First execute the regular SQL
			const result = await this.executeSql(sqlQuery);
			
			if (!result.success) {
				return result;
			}

			// Process results to resolve any chunked content references
			const enhancedResults = await this.resolveChunkedContentInResults(result.results);

			return {
				...result,
				results: enhancedResults,
				chunked_content_resolved: enhancedResults.length !== result.results.length || 
					JSON.stringify(enhancedResults) !== JSON.stringify(result.results)
			};

		} catch (error) {
			return {
				success: false,
				error: error instanceof Error ? error.message : "Enhanced SQL execution failed",
				query: sqlQuery
			};
		}
	}

	/**
	 * Resolves chunked content references in SQL results
	 */
	private async resolveChunkedContentInResults(results: any[]): Promise<any[]> {
		const resolvedResults = [];

		for (const row of results) {
			const resolvedRow: any = {};
			
			for (const [key, value] of Object.entries(row)) {
				if (this.chunkingEngine.isContentReference(value)) {
					try {
						const contentId = this.chunkingEngine.extractContentId(value as string);
						const resolvedContent = await this.chunkingEngine.retrieveChunkedContent(
							contentId, 
							this.ctx.storage.sql
						);
						
						if (resolvedContent !== null) {
							// Try to parse as JSON if it looks like JSON
							try {
								resolvedRow[key] = JSON.parse(resolvedContent);
							} catch {
								// If not valid JSON, return as string
								resolvedRow[key] = resolvedContent;
							}
						} else {
							resolvedRow[key] = `[CHUNKED_CONTENT_NOT_FOUND:${contentId}]`;
						}
					} catch (error) {
						console.error(`Failed to resolve chunked content for ${key}:`, error);
						resolvedRow[key] = `[CHUNKED_CONTENT_ERROR:${error}]`;
					}
				} else {
					resolvedRow[key] = value;
				}
			}
			
			resolvedResults.push(resolvedRow);
		}

		return resolvedResults;
	}

	/**
	 * Initialize schema-aware chunking from Open Targets GraphQL schema content
	 */
	async initializeSchemaAwareChunking(schemaContent: string): Promise<any> {
		try {
			// Parse the GraphQL schema
			const schemaParser = new SchemaParser();
			const schemaInfo = schemaParser.parseSchemaContent(schemaContent);
			
			// Configure the chunking engine with schema awareness
			this.chunkingEngine.configureSchemaAwareness(schemaInfo);
			
			// Get extraction rules and relationships
			const extractionRules = schemaParser.getExtractionRules();
			const relationships = schemaParser.getRelationships();
			
			return {
				success: true,
				message: "Open Targets schema-aware chunking initialized successfully",
				schema_analysis: {
					total_types: Object.keys(schemaInfo.types).length,
					relationships_count: schemaInfo.relationships.length,
					extraction_rules_generated: extractionRules.length,
					entity_relationships: relationships.length
				},
				recommendations: [
					"Schema-aware chunking is now active for Open Targets data patterns",
					"Large content fields (tractability, associations, etc.) will be automatically detected and chunked",
					"Use the /chunking-analysis endpoint to monitor effectiveness",
					"Consider testing with real Open Targets queries to validate chunking decisions"
				]
			};
		} catch (error) {
			return {
				success: false,
				error: error instanceof Error ? error.message : "Schema initialization failed",
				suggestion: "Ensure the schema content is valid Open Targets GraphQL schema definition"
			};
		}
	}

	private validateAnalyticalSql(sql: string): {isValid: boolean, error?: string, queryType?: string} {
		const trimmedSql = sql.trim().toLowerCase();
		
		// Allowed operations for analytical work
		const allowedStarters = [
			'select',
			'with',           // CTEs for complex analysis
			'pragma',         // Schema inspection
			'explain',        // Query planning
			'create temporary table',
			'create temp table',
			'create view',
			'create temporary view',
			'create temp view',
			'drop view',      // Clean up session views
			'drop temporary table',
			'drop temp table'
		];

		// Dangerous operations that modify permanent data
		const blockedPatterns = [
			/\bdrop\s+table\s+(?!temp|temporary)/i,    // Block permanent table drops
			/\bdelete\s+from/i,                        // Block data deletion
			/\bupdate\s+\w+\s+set/i,                   // Block data updates
			/\binsert\s+into\s+(?!temp|temporary)/i,   // Block permanent inserts
			/\balter\s+table/i,                        // Block schema changes
			/\bcreate\s+table\s+(?!temp|temporary)/i,  // Block permanent table creation
			/\battach\s+database/i,                    // Block external database access
			/\bdetach\s+database/i                     // Block database detachment
		];

		// Check if query starts with allowed operation
		const startsWithAllowed = allowedStarters.some(starter => 
			trimmedSql.startsWith(starter)
		);

		if (!startsWithAllowed) {
			return {
				isValid: false, 
				error: `Query type not allowed. Permitted operations: ${allowedStarters.join(', ')}`
			};
		}

		// Check for blocked patterns
		for (const pattern of blockedPatterns) {
			if (pattern.test(sql)) {
				return {
					isValid: false,
					error: `Operation blocked for security: ${pattern.source}`
				};
			}
		}

		// Determine query type for response metadata
		let queryType = 'select';
		if (trimmedSql.startsWith('with')) queryType = 'cte';
		else if (trimmedSql.startsWith('pragma')) queryType = 'pragma';
		else if (trimmedSql.startsWith('explain')) queryType = 'explain';
		else if (trimmedSql.includes('create')) queryType = 'create_temp';

		return {isValid: true, queryType};
	}

	private async createTables(schemas: Record<string, TableSchema>): Promise<void> {
		for (const [tableName, schema] of Object.entries(schemas)) {
			try {
				// Validate table name
				const validTableName = this.validateAndFixIdentifier(tableName, 'table');
				
				// Validate and fix column definitions
				const validColumnDefs: string[] = [];
				for (const [name, type] of Object.entries(schema.columns)) {
					const validColumnName = this.validateAndFixIdentifier(name, 'column');
					const validType = this.validateSQLiteType(type);
					validColumnDefs.push(`${validColumnName} ${validType}`);
				}

				if (validColumnDefs.length === 0) {
					console.warn(`Skipping table ${tableName} - no valid columns`);
					continue;
				}

				const createTableSQL = `CREATE TABLE IF NOT EXISTS ${validTableName} (${validColumnDefs.join(', ')})`;
				
				// Add logging for debugging
				console.log(`Creating table with SQL: ${createTableSQL}`);
				
				this.ctx.storage.sql.exec(createTableSQL);
			} catch (error) {
				console.error(`Error creating table ${tableName}:`, error);
				// Try to create a fallback table with safe defaults
				try {
					const fallbackTableName = this.validateAndFixIdentifier(tableName, 'table');
					const fallbackSQL = `CREATE TABLE IF NOT EXISTS ${fallbackTableName} (id INTEGER PRIMARY KEY AUTOINCREMENT, data_json TEXT)`;
					this.ctx.storage.sql.exec(fallbackSQL);
				} catch (fallbackError) {
					console.error(`Failed to create fallback table for ${tableName}:`, fallbackError);
					// Skip this table entirely
				}
			}
		}
	}

	private validateAndFixIdentifier(name: string, type: 'table' | 'column'): string {
		if (!name || typeof name !== 'string') {
			return type === 'table' ? 'fallback_table' : 'fallback_column';
		}

		// Remove or replace problematic characters
		let fixed = name
			.replace(/[^a-zA-Z0-9_]/g, '_')
			.replace(/_{2,}/g, '_')
			.replace(/^_|_$/g, '');

		// Ensure it doesn't start with a number
		if (/^[0-9]/.test(fixed)) {
			fixed = (type === 'table' ? 'table_' : 'col_') + fixed;
		}

		// Ensure it's not empty
		if (!fixed || fixed.length === 0) {
			fixed = type === 'table' ? 'fallback_table' : 'fallback_column';
		}

		// Handle SQL reserved words by adding suffix
		const reservedWords = [
			'table', 'index', 'view', 'column', 'primary', 'key', 'foreign', 'constraint',
			'order', 'group', 'select', 'from', 'where', 'insert', 'update', 'delete',
			'create', 'drop', 'alter', 'join', 'inner', 'outer', 'left', 'right',
			'union', 'all', 'distinct', 'having', 'limit', 'offset', 'as', 'on'
		];
		
		if (reservedWords.includes(fixed.toLowerCase())) {
			fixed = fixed + (type === 'table' ? '_tbl' : '_col');
		}

		return fixed.toLowerCase();
	}

	private validateSQLiteType(type: string): string {
		if (!type || typeof type !== 'string') {
			return 'TEXT';
		}

		const upperType = type.toUpperCase();
		
		// Map common types to valid SQLite types
		const validTypes = [
			'INTEGER', 'REAL', 'TEXT', 'BLOB', 'NUMERIC',
			'INTEGER PRIMARY KEY', 'INTEGER PRIMARY KEY AUTOINCREMENT',
			'JSON'  // SQLite supports JSON since 3.38
		];

		// Check if it's already a valid type
		if (validTypes.some(validType => upperType.includes(validType))) {
			return type;
		}

		// Map common type variations
		const typeMap: Record<string, string> = {
			'STRING': 'TEXT',
			'VARCHAR': 'TEXT',
			'CHAR': 'TEXT',
			'CLOB': 'TEXT',
			'INT': 'INTEGER',
			'BIGINT': 'INTEGER',
			'SMALLINT': 'INTEGER',
			'TINYINT': 'INTEGER',
			'FLOAT': 'REAL',
			'DOUBLE': 'REAL',
			'DECIMAL': 'NUMERIC',
			'BOOLEAN': 'INTEGER',
			'BOOL': 'INTEGER',
			'DATE': 'TEXT',
			'DATETIME': 'TEXT',
			'TIMESTAMP': 'TEXT'
		};

		return typeMap[upperType] || 'TEXT';
	}

	private async generateMetadata(schemas: Record<string, TableSchema>): Promise<Partial<ProcessingResult>> {
		const metadata: Partial<ProcessingResult> = {
			schemas: {},
			table_count: Object.keys(schemas).length,
			total_rows: 0
		};

		for (const [tableName, schema] of Object.entries(schemas)) {
			try {
				const countResult = this.ctx.storage.sql.exec(`SELECT COUNT(*) as count FROM ${tableName}`);
				const countRow = countResult.one();
				const rowCount = typeof countRow?.count === 'number' ? countRow.count : 0;

				const sampleResult = this.ctx.storage.sql.exec(`SELECT * FROM ${tableName} LIMIT 3`);
				const sampleData = sampleResult.toArray();

				metadata.schemas![tableName] = {
					columns: schema.columns,
					row_count: rowCount,
					sample_data: sampleData
				};

				metadata.total_rows! += rowCount;

			} catch (error) {
				// Continue with other tables on error
				continue;
			}
		}

		return metadata;
	}

	async getSchemaInfo(): Promise<any> {
		try {
			const tables = this.ctx.storage.sql.exec(`
				SELECT name, type 
				FROM sqlite_master 
				WHERE type IN ('table', 'view') 
				ORDER BY name
			`).toArray();

			const schemaInfo: any = {
				database_summary: {
					total_tables: tables.length,
					table_names: tables.map(t => String(t.name))
				},
				tables: {}
			};

			for (const table of tables) {
				const tableName = String(table.name);
				if (!tableName || tableName === 'undefined' || tableName === 'null') {
					continue; // Skip invalid table names
				}
				
				try {
					// Get column information
					const columns = this.ctx.storage.sql.exec(`PRAGMA table_info(${tableName})`).toArray();
					
					// Get row count
					const countResult = this.ctx.storage.sql.exec(`SELECT COUNT(*) as count FROM ${tableName}`).one();
					const rowCount = typeof countResult?.count === 'number' ? countResult.count : 0;
					
					// Get sample data (first 3 rows)
					const sampleData = this.ctx.storage.sql.exec(`SELECT * FROM ${tableName} LIMIT 3`).toArray();
					
					// Get foreign key information
					const foreignKeys = this.ctx.storage.sql.exec(`PRAGMA foreign_key_list(${tableName})`).toArray();
					
					// Get indexes
					const indexes = this.ctx.storage.sql.exec(`PRAGMA index_list(${tableName})`).toArray();

					schemaInfo.tables[tableName] = {
						type: String(table.type),
						row_count: rowCount,
						columns: columns.map((col: any) => ({
							name: String(col.name),
							type: String(col.type),
							not_null: Boolean(col.notnull),
							default_value: col.dflt_value,
							primary_key: Boolean(col.pk)
						})),
						foreign_keys: foreignKeys.map((fk: any) => ({
							column: String(fk.from),
							references_table: String(fk.table),
							references_column: String(fk.to)
						})),
						indexes: indexes.map((idx: any) => ({
							name: String(idx.name),
							unique: Boolean(idx.unique)
						})),
						sample_data: sampleData
					};
				} catch (tableError) {
					// Skip this table if there's an error processing it
					console.error(`Error processing table ${tableName}:`, tableError);
					continue;
				}
			}

			return {
				success: true,
				schema_info: schemaInfo
			};
		} catch (error) {
			return {
				success: false,
				error: error instanceof Error ? error.message : "Schema inspection failed"
			};
		}
	}

	async getTableColumns(tableName: string): Promise<any> {
		try {
			const columns = this.ctx.storage.sql.exec(`PRAGMA table_info(${tableName})`).toArray();
			const foreignKeys = this.ctx.storage.sql.exec(`PRAGMA foreign_key_list(${tableName})`).toArray();
			
			return {
				success: true,
				table: tableName,
				columns: columns.map((col: any) => {
					const fkRef = foreignKeys.find((fk: any) => fk.from === col.name);
					return {
						name: col.name,
						type: col.type,
						not_null: Boolean(col.notnull),
						default_value: col.dflt_value,
						primary_key: Boolean(col.pk),
						is_foreign_key: Boolean(fkRef),
						references: fkRef ? {
							table: fkRef.table,
							column: fkRef.to
						} : null
					};
				})
			};
		} catch (error) {
			return {
				success: false,
				error: error instanceof Error ? error.message : "Table inspection failed"
			};
		}
	}

	async generateAnalyticalQueries(tableName?: string): Promise<any> {
		try {
			const suggestions: any = {
				schema_discovery: [
					"PRAGMA table_list",
					"SELECT name FROM sqlite_master WHERE type='table'",
					tableName ? `PRAGMA table_info(${tableName})` : "-- Specify table name for column info"
				],
				json_analysis: [
					"-- SQLite JSON functions for analyzing Open Targets data:",
					"SELECT json_extract(column_name, '$.field') FROM table_name",
					"SELECT json_array_length(column_name) FROM table_name WHERE column_name IS NOT NULL",
					"SELECT json_each.value FROM table_name, json_each(table_name.column_name)"
				],
				statistical_analysis: [
					"-- Basic statistics:",
					"SELECT COUNT(*), AVG(numeric_column), MIN(numeric_column), MAX(numeric_column) FROM table_name",
					"-- Distribution analysis:",
					"SELECT column_name, COUNT(*) as frequency FROM table_name GROUP BY column_name ORDER BY frequency DESC",
					"-- Cross-table analysis with CTEs:",
					"WITH summary AS (SELECT ...) SELECT * FROM summary WHERE ..."
				],
				open_targets_specific: [
					"-- Target-disease associations by score:",
					"SELECT t.approved_symbol, d.name, a.score FROM target t JOIN association a ON t.id = a.target_id JOIN disease d ON a.disease_id = d.id ORDER BY a.score DESC",
					"-- Top targets by tractability:",
					"SELECT approved_symbol, name, json_extract(tractability_json, '$.score') as tractability_score FROM target WHERE tractability_json IS NOT NULL",
					"-- Drug mechanisms of action:",
					"SELECT name, json_extract(mechanisms_of_action_json, '$[*].mechanismOfAction') FROM drug WHERE mechanisms_of_action_json IS NOT NULL",
					"-- Disease therapeutic areas:",
					"SELECT name, json_extract(therapeutic_areas_json, '$[*].name') FROM disease WHERE therapeutic_areas_json IS NOT NULL"
				]
			};

			return {
				success: true,
				query_suggestions: suggestions
			};
		} catch (error) {
			return {
				success: false,
				error: error instanceof Error ? error.message : "Query generation failed"
			};
		}
	}

	async fetch(request: Request): Promise<Response> {
		const url = new URL(request.url);

		try {
			if (url.pathname === '/process' && request.method === 'POST') {
				const jsonData = await request.json();
				const result = await this.processAndStoreJson(jsonData);
				return new Response(JSON.stringify(result), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/query' && request.method === 'POST') {
				const { sql } = await request.json() as { sql: string };
				const result = await this.executeSql(sql);
				return new Response(JSON.stringify(result), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/schema' && request.method === 'GET') {
				const result = await this.getSchemaInfo();
				return new Response(JSON.stringify(result), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/table-info' && request.method === 'POST') {
				const { table_name } = await request.json() as { table_name: string };
				const result = await this.getTableColumns(table_name);
				return new Response(JSON.stringify(result), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/query-suggestions' && request.method === 'GET') {
				const tableName = url.searchParams.get('table');
				const result = await this.generateAnalyticalQueries(tableName || undefined);
				return new Response(JSON.stringify(result), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/query-enhanced' && request.method === 'POST') {
				const { sql } = await request.json() as { sql: string };
				const result = await this.executeEnhancedSql(sql);
				return new Response(JSON.stringify(result), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/chunking-stats' && request.method === 'GET') {
				const result = await this.chunkingEngine.getChunkingStats(this.ctx.storage.sql);
				return new Response(JSON.stringify({
					success: true,
					chunking_statistics: result
				}), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/initialize-schema' && request.method === 'POST') {
				const { schemaContent } = await request.json() as { schemaContent: string };
				const result = await this.initializeSchemaAwareChunking(schemaContent);
				return new Response(JSON.stringify(result), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/chunking-analysis' && request.method === 'GET') {
				const result = await this.chunkingEngine.analyzeChunkingEffectiveness(this.ctx.storage.sql);
				return new Response(JSON.stringify({
					success: true,
					analysis: result
				}), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else if (url.pathname === '/delete' && request.method === 'DELETE') {
				await this.ctx.storage.deleteAll();
				return new Response(JSON.stringify({ success: true }), {
					headers: { 'Content-Type': 'application/json' }
				});
			} else {
				return new Response('Not Found', { status: 404 });
			}
		} catch (error) {
			return new Response(JSON.stringify({
				error: error instanceof Error ? error.message : 'Unknown error'
			}), {
				status: 500,
				headers: { 'Content-Type': 'application/json' }
			});
		}
	}
} 
--------------------------------------------------------------------------------
END OF FILE: src/do.ts
--------------------------------------------------------------------------------


================================================================================
FILE: wrangler.jsonc
================================================================================

/**
 * For more details on how to configure Wrangler, refer to:
 * https://developers.cloudflare.com/workers/wrangler/configuration/
 */
{
	"$schema": "node_modules/wrangler/config-schema.json",
	"name": "open-targets-mcp-server",
	"main": "src/index.ts",
	"compatibility_date": "2025-03-10",
	"compatibility_flags": ["nodejs_compat"],
	"migrations": [
		{
			"new_sqlite_classes": ["MyMCP"],
			"tag": "v1"
		},
		{
			"tag": "v2-json-to-sql-do",
			"new_sqlite_classes": ["JsonToSqlDO"]
		}
	],
	"durable_objects": {
		"bindings": [
			{
				"class_name": "MyMCP",
				"name": "MCP_OBJECT"
			},
			{
				"name": "JSON_TO_SQL_DO",
				"class_name": "JsonToSqlDO"
			}
		]
	},
	"observability": {
		"enabled": true
	}
}
--------------------------------------------------------------------------------
END OF FILE: wrangler.jsonc
--------------------------------------------------------------------------------


